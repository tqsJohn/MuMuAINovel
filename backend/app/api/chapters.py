"""ç« èŠ‚ç®¡ç†API"""
from fastapi import APIRouter, Depends, HTTPException, Request, Query, BackgroundTasks
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
import json
import asyncio
from typing import Optional
from datetime import datetime
from asyncio import Queue, Lock

from app.database import get_db
from app.models.chapter import Chapter
from app.models.project import Project
from app.models.outline import Outline
from app.models.character import Character
from app.models.generation_history import GenerationHistory
from app.models.writing_style import WritingStyle
from app.models.analysis_task import AnalysisTask
from app.models.memory import PlotAnalysis, StoryMemory
from app.schemas.chapter import (
    ChapterCreate,
    ChapterUpdate,
    ChapterResponse,
    ChapterListResponse,
    ChapterGenerateRequest
)
from app.services.ai_service import AIService
from app.services.prompt_service import prompt_service
from app.services.plot_analyzer import PlotAnalyzer
from app.services.memory_service import memory_service
from app.logger import get_logger
from app.api.settings import get_user_ai_service

router = APIRouter(prefix="/chapters", tags=["ç« èŠ‚ç®¡ç†"])
logger = get_logger(__name__)

# å…¨å±€æ•°æ®åº“å†™å…¥é”ï¼ˆæ¯ä¸ªç”¨æˆ·ä¸€ä¸ªé”ï¼Œç”¨äºä¿æŠ¤SQLiteå†™å…¥æ“ä½œï¼‰
db_write_locks: dict[str, Lock] = {}


async def get_db_write_lock(user_id: str) -> Lock:
    """è·å–æˆ–åˆ›å»ºç”¨æˆ·çš„æ•°æ®åº“å†™å…¥é”"""
    if user_id not in db_write_locks:
        db_write_locks[user_id] = Lock()
        logger.debug(f"ğŸ”’ ä¸ºç”¨æˆ· {user_id} åˆ›å»ºæ•°æ®åº“å†™å…¥é”")
    return db_write_locks[user_id]


@router.post("", response_model=ChapterResponse, summary="åˆ›å»ºç« èŠ‚")
async def create_chapter(
    chapter: ChapterCreate,
    db: AsyncSession = Depends(get_db)
):
    """åˆ›å»ºæ–°çš„ç« èŠ‚"""
    # éªŒè¯é¡¹ç›®æ˜¯å¦å­˜åœ¨
    result = await db.execute(
        select(Project).where(Project.id == chapter.project_id)
    )
    project = result.scalar_one_or_none()
    if not project:
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
    
    # è®¡ç®—å­—æ•°
    word_count = len(chapter.content)
    
    db_chapter = Chapter(
        **chapter.model_dump(),
        word_count=word_count
    )
    db.add(db_chapter)
    
    # æ›´æ–°é¡¹ç›®çš„å½“å‰å­—æ•°
    project.current_words = project.current_words + word_count
    
    await db.commit()
    await db.refresh(db_chapter)
    return db_chapter


@router.get("/project/{project_id}", response_model=ChapterListResponse, summary="è·å–é¡¹ç›®çš„æ‰€æœ‰ç« èŠ‚")
async def get_project_chapters(
    project_id: str,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šé¡¹ç›®çš„æ‰€æœ‰ç« èŠ‚ï¼ˆè·¯å¾„å‚æ•°ç‰ˆæœ¬ï¼‰"""
    # è·å–æ€»æ•°
    count_result = await db.execute(
        select(func.count(Chapter.id)).where(Chapter.project_id == project_id)
    )
    total = count_result.scalar_one()
    
    # è·å–ç« èŠ‚åˆ—è¡¨
    result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == project_id)
        .order_by(Chapter.chapter_number)
    )
    chapters = result.scalars().all()
    
    return ChapterListResponse(total=total, items=chapters)


@router.get("/{chapter_id}", response_model=ChapterResponse, summary="è·å–ç« èŠ‚è¯¦æƒ…")
async def get_chapter(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """æ ¹æ®IDè·å–ç« èŠ‚è¯¦æƒ…"""
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    return chapter


@router.get("/{chapter_id}/navigation", summary="è·å–ç« èŠ‚å¯¼èˆªä¿¡æ¯")
async def get_chapter_navigation(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„å¯¼èˆªä¿¡æ¯ï¼ˆä¸Šä¸€ç« /ä¸‹ä¸€ç« ï¼‰
    ç”¨äºç« èŠ‚é˜…è¯»å™¨çš„ç¿»é¡µåŠŸèƒ½
    """
    # è·å–å½“å‰ç« èŠ‚
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    current_chapter = result.scalar_one_or_none()
    
    if not current_chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # è·å–ä¸Šä¸€ç« 
    prev_result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == current_chapter.project_id)
        .where(Chapter.chapter_number < current_chapter.chapter_number)
        .order_by(Chapter.chapter_number.desc())
        .limit(1)
    )
    prev_chapter = prev_result.scalar_one_or_none()
    
    # è·å–ä¸‹ä¸€ç« 
    next_result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == current_chapter.project_id)
        .where(Chapter.chapter_number > current_chapter.chapter_number)
        .order_by(Chapter.chapter_number.asc())
        .limit(1)
    )
    next_chapter = next_result.scalar_one_or_none()
    
    return {
        "current": {
            "id": current_chapter.id,
            "chapter_number": current_chapter.chapter_number,
            "title": current_chapter.title
        },
        "previous": {
            "id": prev_chapter.id,
            "chapter_number": prev_chapter.chapter_number,
            "title": prev_chapter.title
        } if prev_chapter else None,
        "next": {
            "id": next_chapter.id,
            "chapter_number": next_chapter.chapter_number,
            "title": next_chapter.title
        } if next_chapter else None
    }


@router.put("/{chapter_id}", response_model=ChapterResponse, summary="æ›´æ–°ç« èŠ‚")
async def update_chapter(
    chapter_id: str,
    chapter_update: ChapterUpdate,
    db: AsyncSession = Depends(get_db)
):
    """æ›´æ–°ç« èŠ‚ä¿¡æ¯"""
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # è®°å½•æ—§å­—æ•°
    old_word_count = chapter.word_count or 0
    
    # æ›´æ–°å­—æ®µ
    update_data = chapter_update.model_dump(exclude_unset=True)
    for field, value in update_data.items():
        setattr(chapter, field, value)
    
    # å¦‚æœå†…å®¹æ›´æ–°äº†ï¼Œé‡æ–°è®¡ç®—å­—æ•°
    if "content" in update_data and chapter.content:
        new_word_count = len(chapter.content)
        chapter.word_count = new_word_count
        
        # æ›´æ–°é¡¹ç›®å­—æ•°
        result = await db.execute(
            select(Project).where(Project.id == chapter.project_id)
        )
        project = result.scalar_one_or_none()
        if project:
            project.current_words = project.current_words - old_word_count + new_word_count
    
    await db.commit()
    await db.refresh(chapter)
    return chapter


@router.delete("/{chapter_id}", summary="åˆ é™¤ç« èŠ‚")
async def delete_chapter(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """åˆ é™¤ç« èŠ‚"""
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # æ›´æ–°é¡¹ç›®å­—æ•°
    result = await db.execute(
        select(Project).where(Project.id == chapter.project_id)
    )
    project = result.scalar_one_or_none()
    if project:
        project.current_words = max(0, project.current_words - chapter.word_count)
    
    await db.delete(chapter)
    await db.commit()
    
    return {"message": "ç« èŠ‚åˆ é™¤æˆåŠŸ"}


async def check_prerequisites(db: AsyncSession, chapter: Chapter) -> tuple[bool, str, list[Chapter]]:
    """
    æ£€æŸ¥ç« èŠ‚å‰ç½®æ¡ä»¶
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        chapter: å½“å‰ç« èŠ‚
        
    Returns:
        (å¯å¦ç”Ÿæˆ, é”™è¯¯ä¿¡æ¯, å‰ç½®ç« èŠ‚åˆ—è¡¨)
    """
    # å¦‚æœæ˜¯ç¬¬ä¸€ç« ï¼Œæ— éœ€æ£€æŸ¥å‰ç½®
    if chapter.chapter_number == 1:
        return True, "", []
    
    # æŸ¥è¯¢æ‰€æœ‰å‰ç½®ç« èŠ‚ï¼ˆåºå·å°äºå½“å‰ç« èŠ‚çš„ï¼‰
    result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == chapter.project_id)
        .where(Chapter.chapter_number < chapter.chapter_number)
        .order_by(Chapter.chapter_number)
    )
    previous_chapters = result.scalars().all()
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‰ç½®ç« èŠ‚éƒ½æœ‰å†…å®¹
    incomplete_chapters = [
        ch for ch in previous_chapters
        if not ch.content or ch.content.strip() == ""
    ]
    
    if incomplete_chapters:
        missing_numbers = [str(ch.chapter_number) for ch in incomplete_chapters]
        error_msg = f"éœ€è¦å…ˆå®Œæˆå‰ç½®ç« èŠ‚ï¼šç¬¬ {', '.join(missing_numbers)} ç« "
        return False, error_msg, previous_chapters
    
    return True, "", previous_chapters


@router.get("/{chapter_id}/can-generate", summary="æ£€æŸ¥ç« èŠ‚æ˜¯å¦å¯ä»¥ç”Ÿæˆ")
async def check_can_generate(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    æ£€æŸ¥ç« èŠ‚æ˜¯å¦æ»¡è¶³ç”Ÿæˆæ¡ä»¶
    è¿”å›å¯ç”ŸæˆçŠ¶æ€å’Œå‰ç½®ç« èŠ‚ä¿¡æ¯
    """
    # è·å–ç« èŠ‚
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    can_generate, error_msg, previous_chapters = await check_prerequisites(db, chapter)
    
    # æ„å»ºå‰ç½®ç« èŠ‚ä¿¡æ¯
    previous_info = [
        {
            "id": ch.id,
            "chapter_number": ch.chapter_number,
            "title": ch.title,
            "has_content": bool(ch.content and ch.content.strip()),
            "word_count": ch.word_count or 0
        }
        for ch in previous_chapters
    ]
    
    return {
        "can_generate": can_generate,
        "reason": error_msg if not can_generate else "",
        "previous_chapters": previous_info,
        "chapter_number": chapter.chapter_number
    }


async def analyze_chapter_background(
    chapter_id: str,
    user_id: str,
    project_id: str,
    task_id: str,
    ai_service: AIService
):
    """
    åå°å¼‚æ­¥åˆ†æç« èŠ‚ï¼ˆæ”¯æŒå¹¶å‘ï¼Œä½¿ç”¨é”ä¿æŠ¤æ•°æ®åº“å†™å…¥ï¼‰
    
    Args:
        chapter_id: ç« èŠ‚ID
        user_id: ç”¨æˆ·ID
        project_id: é¡¹ç›®ID
        task_id: ä»»åŠ¡ID
        ai_service: AIæœåŠ¡å®ä¾‹
    """
    db_session = None
    write_lock = await get_db_write_lock(user_id)
    
    try:
        logger.info(f"ğŸ” å¼€å§‹åˆ†æç« èŠ‚: {chapter_id}, ä»»åŠ¡ID: {task_id}")
        
        # åˆ›å»ºç‹¬ç«‹æ•°æ®åº“ä¼šè¯
        from app.database import get_engine
        from sqlalchemy.ext.asyncio import async_sessionmaker, AsyncSession
        
        engine = await get_engine(user_id)
        AsyncSessionLocal = async_sessionmaker(
            engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
        db_session = AsyncSessionLocal()
        
        # 1. è·å–ä»»åŠ¡ï¼ˆè¯»æ“ä½œï¼‰
        task_result = await db_session.execute(
            select(AnalysisTask).where(AnalysisTask.id == task_id)
        )
        task = task_result.scalar_one_or_none()
        
        if not task:
            logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            task.status = 'running'
            task.started_at = datetime.now()
            task.progress = 10
            await db_session.commit()
        
        # 2. è·å–ç« èŠ‚ä¿¡æ¯ï¼ˆè¯»æ“ä½œï¼‰
        chapter_result = await db_session.execute(
            select(Chapter).where(Chapter.id == chapter_id)
        )
        chapter = chapter_result.scalar_one_or_none()
        if not chapter or not chapter.content:
            async with write_lock:
                task.status = 'failed'
                task.error_message = 'ç« èŠ‚ä¸å­˜åœ¨æˆ–å†…å®¹ä¸ºç©º'
                task.completed_at = datetime.now()
                await db_session.commit()
            logger.error(f"âŒ ç« èŠ‚ä¸å­˜åœ¨æˆ–å†…å®¹ä¸ºç©º: {chapter_id}")
            return
        
        async with write_lock:
            task.progress = 20
            await db_session.commit()
        
        # 3. ä½¿ç”¨PlotAnalyzeråˆ†æç« èŠ‚
        analyzer = PlotAnalyzer(ai_service)
        analysis_result = await analyzer.analyze_chapter(
            chapter_number=chapter.chapter_number,
            title=chapter.title,
            content=chapter.content,
            word_count=chapter.word_count or len(chapter.content)
        )
        
        if not analysis_result:
            async with write_lock:
                task.status = 'failed'
                task.error_message = 'AIåˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—'
                task.completed_at = datetime.now()
                await db_session.commit()
            logger.error(f"âŒ AIåˆ†æå¤±è´¥: {chapter_id}")
            return
        
        async with write_lock:
            task.progress = 60
            await db_session.commit()
        
        # 4. ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            existing_analysis_result = await db_session.execute(
                select(PlotAnalysis).where(PlotAnalysis.chapter_id == chapter_id)
            )
            existing_analysis = existing_analysis_result.scalar_one_or_none()
            
            if existing_analysis:
                # æ›´æ–°ç°æœ‰è®°å½•
                logger.info(f"  æ›´æ–°ç°æœ‰åˆ†æè®°å½•: {existing_analysis.id}")
                existing_analysis.plot_stage = analysis_result.get('plot_stage', 'å‘å±•')
                existing_analysis.conflict_level = analysis_result.get('conflict', {}).get('level', 0)
                existing_analysis.conflict_types = analysis_result.get('conflict', {}).get('types', [])
                existing_analysis.emotional_tone = analysis_result.get('emotional_arc', {}).get('primary_emotion', '')
                existing_analysis.emotional_intensity = analysis_result.get('emotional_arc', {}).get('intensity', 0) / 10.0
                existing_analysis.hooks = analysis_result.get('hooks', [])
                existing_analysis.hooks_count = len(analysis_result.get('hooks', []))
                existing_analysis.foreshadows = analysis_result.get('foreshadows', [])
                existing_analysis.foreshadows_planted = sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'planted')
                existing_analysis.foreshadows_resolved = sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'resolved')
                existing_analysis.plot_points = analysis_result.get('plot_points', [])
                existing_analysis.plot_points_count = len(analysis_result.get('plot_points', []))
                existing_analysis.character_states = analysis_result.get('character_states', [])
                existing_analysis.scenes = analysis_result.get('scenes', [])
                existing_analysis.pacing = analysis_result.get('pacing', 'moderate')
                existing_analysis.overall_quality_score = analysis_result.get('scores', {}).get('overall', 0)
                existing_analysis.pacing_score = analysis_result.get('scores', {}).get('pacing', 0)
                existing_analysis.engagement_score = analysis_result.get('scores', {}).get('engagement', 0)
                existing_analysis.coherence_score = analysis_result.get('scores', {}).get('coherence', 0)
                existing_analysis.analysis_report = analyzer.generate_analysis_summary(analysis_result)
                existing_analysis.suggestions = analysis_result.get('suggestions', [])
                existing_analysis.dialogue_ratio = analysis_result.get('dialogue_ratio', 0)
                existing_analysis.description_ratio = analysis_result.get('description_ratio', 0)
            else:
                # åˆ›å»ºæ–°è®°å½•
                logger.info(f"  åˆ›å»ºæ–°çš„åˆ†æè®°å½•")
                plot_analysis = PlotAnalysis(
                    chapter_id=chapter_id,
                    project_id=project_id,
                    plot_stage=analysis_result.get('plot_stage', 'å‘å±•'),
                    conflict_level=analysis_result.get('conflict', {}).get('level', 0),
                    conflict_types=analysis_result.get('conflict', {}).get('types', []),
                    emotional_tone=analysis_result.get('emotional_arc', {}).get('primary_emotion', ''),
                    emotional_intensity=analysis_result.get('emotional_arc', {}).get('intensity', 0) / 10.0,
                    hooks=analysis_result.get('hooks', []),
                    hooks_count=len(analysis_result.get('hooks', [])),
                    foreshadows=analysis_result.get('foreshadows', []),
                    foreshadows_planted=sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'planted'),
                    foreshadows_resolved=sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'resolved'),
                    plot_points=analysis_result.get('plot_points', []),
                    plot_points_count=len(analysis_result.get('plot_points', [])),
                    character_states=analysis_result.get('character_states', []),
                    scenes=analysis_result.get('scenes', []),
                    pacing=analysis_result.get('pacing', 'moderate'),
                    overall_quality_score=analysis_result.get('scores', {}).get('overall', 0),
                    pacing_score=analysis_result.get('scores', {}).get('pacing', 0),
                    engagement_score=analysis_result.get('scores', {}).get('engagement', 0),
                    coherence_score=analysis_result.get('scores', {}).get('coherence', 0),
                    analysis_report=analyzer.generate_analysis_summary(analysis_result),
                    suggestions=analysis_result.get('suggestions', []),
                    dialogue_ratio=analysis_result.get('dialogue_ratio', 0),
                    description_ratio=analysis_result.get('description_ratio', 0)
                )
                db_session.add(plot_analysis)
            
            await db_session.commit()
            
            task.progress = 80
            await db_session.commit()
        
        # 5. æå–è®°å¿†å¹¶ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ï¼ˆä¼ å…¥ç« èŠ‚å†…å®¹ç”¨äºè®¡ç®—ä½ç½®ï¼‰
        memories = analyzer.extract_memories_from_analysis(
            analysis=analysis_result,
            chapter_id=chapter_id,
            chapter_number=chapter.chapter_number,
            chapter_content=chapter.content or ""
        )
        
        # å…ˆåˆ é™¤è¯¥ç« èŠ‚çš„æ—§è®°å¿†ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            old_memories_result = await db_session.execute(
                select(StoryMemory).where(StoryMemory.chapter_id == chapter_id)
            )
            old_memories = old_memories_result.scalars().all()
            for old_mem in old_memories:
                await db_session.delete(old_mem)
            await db_session.commit()
            logger.info(f"  åˆ é™¤æ—§è®°å¿†: {len(old_memories)}æ¡")
        
        # å‡†å¤‡æ‰¹é‡æ·»åŠ çš„è®°å¿†æ•°æ®ï¼ˆä¸éœ€è¦é”ï¼‰
        memory_records = []
        for mem in memories:
            memory_id = f"{chapter_id}_{mem['type']}_{len(memory_records)}"
            memory_records.append({
                'id': memory_id,
                'content': mem['content'],
                'type': mem['type'],
                'metadata': mem['metadata']
            })
            
        # ä¿å­˜åˆ°å…³ç³»æ•°æ®åº“ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            for mem in memories:
                memory_id = memory_records[memories.index(mem)]['id']
                text_position = mem['metadata'].get('text_position', -1)
                text_length = mem['metadata'].get('text_length', 0)
                
                story_memory = StoryMemory(
                    id=memory_id,
                    project_id=project_id,
                    chapter_id=chapter_id,
                    memory_type=mem['type'],
                    content=mem['content'],
                    title=mem['title'],
                    importance_score=mem['metadata'].get('importance_score', 0.5),
                    tags=mem['metadata'].get('tags', []),
                    is_foreshadow=mem['metadata'].get('is_foreshadow', 0),
                    story_timeline=chapter.chapter_number,
                    chapter_position=text_position,
                    text_length=text_length,
                    related_characters=mem['metadata'].get('related_characters', []),
                    related_locations=mem['metadata'].get('related_locations', [])
                )
                db_session.add(story_memory)
                
                if text_position >= 0:
                    logger.debug(f"  ä¿å­˜è®°å¿† {memory_id}: position={text_position}, length={text_length}")
            
            await db_session.commit()
        
        # æ‰¹é‡æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        if memory_records:
            added_count = await memory_service.batch_add_memories(
                user_id=user_id,
                project_id=project_id,
                memories=memory_records
            )
            logger.info(f"âœ… æ·»åŠ {added_count}æ¡è®°å¿†åˆ°å‘é‡åº“")
        
        # æœ€ç»ˆæ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰- å¢åŠ é‡è¯•æœºåˆ¶
        update_success = False
        for retry in range(3):
            try:
                async with write_lock:
                    task.progress = 100
                    task.status = 'completed'
                    task.completed_at = datetime.now()
                    await db_session.commit()
                    update_success = True
                    logger.info(f"âœ… ç« èŠ‚åˆ†æå®Œæˆ: {chapter_id}, æå–{len(memories)}æ¡è®°å¿†")
                    break
            except Exception as commit_error:
                logger.error(f"âŒ æäº¤ä»»åŠ¡å®ŒæˆçŠ¶æ€å¤±è´¥(é‡è¯•{retry+1}/3): {str(commit_error)}")
                if retry < 2:
                    await asyncio.sleep(0.1)
                else:
                    logger.error(f"âŒ æ— æ³•æ›´æ–°ä»»åŠ¡ä¸ºcompletedçŠ¶æ€: {task_id}")
                    # å³ä½¿å¤±è´¥ä¹Ÿä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå› ä¸ºåˆ†ææœ¬èº«å·²ç»å®Œæˆ
        
        if not update_success:
            logger.warning(f"âš ï¸  ç« èŠ‚åˆ†æå®Œæˆä½†çŠ¶æ€æ›´æ–°å¤±è´¥: {chapter_id}")
        
    except Exception as e:
        logger.error(f"âŒ åå°åˆ†æå¼‚å¸¸: {str(e)}", exc_info=True)
        # ç¡®ä¿ä»»åŠ¡çŠ¶æ€è¢«æ›´æ–°ä¸ºfailedï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        if db_session:
            # å¤šæ¬¡é‡è¯•æ›´æ–°ä»»åŠ¡çŠ¶æ€
            for retry in range(3):
                try:
                    async with write_lock:
                        # é‡æ–°è·å–ä»»åŠ¡ï¼ˆå¯èƒ½æ˜¯æ—§ä¼šè¯å¯¼è‡´çš„é—®é¢˜ï¼‰
                        task_result = await db_session.execute(
                            select(AnalysisTask).where(AnalysisTask.id == task_id)
                        )
                        task = task_result.scalar_one_or_none()
                        if task:
                            task.status = 'failed'
                            task.error_message = str(e)[:500]
                            task.completed_at = datetime.now()
                            task.progress = 0
                            await db_session.commit()
                            logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸ºfailed: {task_id} (é‡è¯•{retry+1}æ¬¡)")
                            break
                        else:
                            logger.error(f"âŒ æ— æ³•æ‰¾åˆ°ä»»åŠ¡è¿›è¡ŒçŠ¶æ€æ›´æ–°: {task_id}")
                            break
                except Exception as update_error:
                    logger.error(f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥(é‡è¯•{retry+1}/3): {str(update_error)}")
                    if retry < 2:
                        await asyncio.sleep(0.1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    else:
                        logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {task_id}")
    finally:
        if db_session:
            await db_session.close()


@router.post("/{chapter_id}/generate-stream", summary="AIåˆ›ä½œç« èŠ‚å†…å®¹ï¼ˆæµå¼ï¼‰")
async def generate_chapter_content_stream(
    chapter_id: str,
    request: Request,
    background_tasks: BackgroundTasks,
    generate_request: ChapterGenerateRequest = ChapterGenerateRequest(),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ ¹æ®å¤§çº²ã€å‰ç½®ç« èŠ‚å†…å®¹å’Œé¡¹ç›®ä¿¡æ¯AIåˆ›ä½œç« èŠ‚å®Œæ•´å†…å®¹ï¼ˆæµå¼è¿”å›ï¼‰
    è¦æ±‚ï¼šå¿…é¡»æŒ‰é¡ºåºç”Ÿæˆï¼Œç¡®ä¿å‰ç½®ç« èŠ‚éƒ½å·²å®Œæˆ
    
    è¯·æ±‚ä½“å‚æ•°ï¼š
    - style_id: å¯é€‰ï¼ŒæŒ‡å®šä½¿ç”¨çš„å†™ä½œé£æ ¼IDã€‚ä¸æä¾›åˆ™ä¸ä½¿ç”¨ä»»ä½•é£æ ¼
    - target_word_count: å¯é€‰ï¼Œç›®æ ‡å­—æ•°ï¼Œé»˜è®¤3000å­—ï¼ŒèŒƒå›´500-10000å­—
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸ä½¿ç”¨ä¾èµ–æ³¨å…¥çš„dbï¼Œè€Œæ˜¯åœ¨ç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
    ä»¥é¿å…æµå¼å“åº”æœŸé—´çš„è¿æ¥æ³„æ¼é—®é¢˜
    """
    style_id = generate_request.style_id
    target_word_count = generate_request.target_word_count or 3000
    # é¢„å…ˆéªŒè¯ç« èŠ‚å­˜åœ¨æ€§ï¼ˆä½¿ç”¨ä¸´æ—¶ä¼šè¯ï¼‰
    async for temp_db in get_db(request):
        try:
            result = await temp_db.execute(
                select(Chapter).where(Chapter.id == chapter_id)
            )
            chapter = result.scalar_one_or_none()
            if not chapter:
                raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            can_generate, error_msg, previous_chapters = await check_prerequisites(temp_db, chapter)
            if not can_generate:
                raise HTTPException(status_code=400, detail=error_msg)
            
            # ä¿å­˜å‰ç½®ç« èŠ‚æ•°æ®ä¾›ç”Ÿæˆå™¨ä½¿ç”¨
            previous_chapters_data = [
                {
                    'id': ch.id,
                    'chapter_number': ch.chapter_number,
                    'title': ch.title,
                    'content': ch.content
                }
                for ch in previous_chapters
            ]
        finally:
            await temp_db.close()
        break
    
    async def event_generator():
        # åœ¨ç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
        db_session = None
        db_committed = False
        # è·å–å½“å‰ç”¨æˆ·IDï¼ˆåœ¨ç”Ÿæˆå™¨å¤–éƒ¨å°±éœ€è¦ï¼‰
        current_user_id = getattr(request.state, "user_id", "system")
        
        try:
            # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
            async for db_session in get_db(request):
                # é‡æ–°è·å–ç« èŠ‚ä¿¡æ¯
                chapter_result = await db_session.execute(
                    select(Chapter).where(Chapter.id == chapter_id)
                )
                current_chapter = chapter_result.scalar_one_or_none()
                if not current_chapter:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'ç« èŠ‚ä¸å­˜åœ¨'}, ensure_ascii=False)}\n\n"
                    return
            
                # è·å–é¡¹ç›®ä¿¡æ¯
                project_result = await db_session.execute(
                    select(Project).where(Project.id == current_chapter.project_id)
                )
                project = project_result.scalar_one_or_none()
                if not project:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'é¡¹ç›®ä¸å­˜åœ¨'}, ensure_ascii=False)}\n\n"
                    return
                
                # è·å–å¯¹åº”çš„å¤§çº²
                outline_result = await db_session.execute(
                    select(Outline)
                    .where(Outline.project_id == current_chapter.project_id)
                    .where(Outline.order_index == current_chapter.chapter_number)
                    .execution_options(populate_existing=True)
                )
                outline = outline_result.scalar_one_or_none()
                
                # è·å–æ‰€æœ‰å¤§çº²ç”¨äºä¸Šä¸‹æ–‡
                all_outlines_result = await db_session.execute(
                    select(Outline)
                    .where(Outline.project_id == current_chapter.project_id)
                    .order_by(Outline.order_index)
                    .execution_options(populate_existing=True)
                )
                all_outlines = all_outlines_result.scalars().all()
                outlines_context = "\n".join([
                    f"ç¬¬{o.order_index}ç«  {o.title}: {o.content[:100]}..."
                    for o in all_outlines
                ])
                
                # è·å–è§’è‰²ä¿¡æ¯
                characters_result = await db_session.execute(
                    select(Character).where(Character.project_id == current_chapter.project_id)
                )
                characters = characters_result.scalars().all()
                characters_info = "\n".join([
                    f"- {c.name}({'ç»„ç»‡' if c.is_organization else 'è§’è‰²'}, {c.role_type}): {c.personality[:100] if c.personality else ''}"
                    for c in characters
                ])
                
                # è·å–å†™ä½œé£æ ¼
                style_content = ""
                if style_id:
                    # ä½¿ç”¨æŒ‡å®šçš„é£æ ¼
                    style_result = await db_session.execute(
                        select(WritingStyle).where(WritingStyle.id == style_id)
                    )
                    style = style_result.scalar_one_or_none()
                    if style:
                        # éªŒè¯é£æ ¼æ˜¯å¦å¯ç”¨ï¼šå…¨å±€é¢„è®¾é£æ ¼ï¼ˆproject_idä¸ºNULLï¼‰æˆ–è€…å½“å‰é¡¹ç›®çš„è‡ªå®šä¹‰é£æ ¼
                        if style.project_id is None or style.project_id == current_chapter.project_id:
                            style_content = style.prompt_content or ""
                            style_type = "å…¨å±€é¢„è®¾" if style.project_id is None else "é¡¹ç›®è‡ªå®šä¹‰"
                            logger.info(f"ä½¿ç”¨æŒ‡å®šé£æ ¼: {style.name} ({style_type})")
                        else:
                            logger.warning(f"é£æ ¼ {style_id} ä¸å±äºå½“å‰é¡¹ç›®ï¼Œæ— æ³•ä½¿ç”¨")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°é£æ ¼ {style_id}")
                else:
                    logger.info("æœªæŒ‡å®šå†™ä½œé£æ ¼ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯")
                
                # æ„å»ºå‰ç½®ç« èŠ‚å†…å®¹ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨ä¹‹å‰ä¿å­˜çš„æ•°æ®ï¼‰
                previous_content = ""
                if previous_chapters_data:
                    recent_chapters = previous_chapters_data[-3:] if len(previous_chapters_data) > 3 else previous_chapters_data
                    early_chapters = previous_chapters_data[:-3] if len(previous_chapters_data) > 3 else []
                    
                    if early_chapters:
                        early_summary = "ã€å‰æœŸå‰§æƒ…æ¦‚è¦ã€‘\n" + "\n".join([
                            f"ç¬¬{ch['chapter_number']}ç« ã€Š{ch['title']}ã€‹ï¼š{ch['content'][:200] if ch['content'] else ''}..."
                            for ch in early_chapters
                        ])
                        previous_content += early_summary + "\n\n"
                    
                    if recent_chapters:
                        recent_content = "ã€æœ€è¿‘ç« èŠ‚å®Œæ•´å†…å®¹ã€‘\n" + "\n\n".join([
                            f"=== ç¬¬{ch['chapter_number']}ç« ï¼š{ch['title']} ===\n{ch['content']}"
                            for ch in recent_chapters
                        ])
                        previous_content += recent_content
                    
                    logger.info(f"æ„å»ºå‰ç½®ä¸Šä¸‹æ–‡ï¼š{len(early_chapters)}ç« æ‘˜è¦ + {len(recent_chapters)}ç« å®Œæ•´å†…å®¹")
                
                # ğŸ§  æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡
                logger.info(f"ğŸ§  å¼€å§‹æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡...")
                memory_context = await memory_service.build_context_for_generation(
                    user_id=current_user_id,
                    project_id=project.id,
                    current_chapter=current_chapter.chapter_number,
                    chapter_outline=outline.content if outline else current_chapter.summary or "",
                    character_names=[c.name for c in characters] if characters else None
                )
                
                # è®¡ç®—å„éƒ¨åˆ†çš„å­—ç¬¦é•¿åº¦
                context_lengths = {
                    'recent_context': len(memory_context.get('recent_context', '')),
                    'relevant_memories': len(memory_context.get('relevant_memories', '')),
                    'foreshadows': len(memory_context.get('foreshadows', '')),
                    'character_states': len(memory_context.get('character_states', '')),
                    'plot_points': len(memory_context.get('plot_points', ''))
                }
                total_memory_length = sum(context_lengths.values())
                
                logger.info(f"âœ… è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: {memory_context['stats']}")
                logger.info(f"ğŸ“ è®°å¿†ä¸Šä¸‹æ–‡é•¿åº¦ç»Ÿè®¡:")
                logger.info(f"  - æœ€è¿‘ç« èŠ‚è®°å¿†: {context_lengths['recent_context']} å­—ç¬¦")
                logger.info(f"  - è¯­ä¹‰ç›¸å…³è®°å¿†: {context_lengths['relevant_memories']} å­—ç¬¦")
                logger.info(f"  - æœªå®Œç»“ä¼ç¬”: {context_lengths['foreshadows']} å­—ç¬¦")
                logger.info(f"  - è§’è‰²çŠ¶æ€è®°å¿†: {context_lengths['character_states']} å­—ç¬¦")
                logger.info(f"  - é‡è¦æƒ…èŠ‚ç‚¹: {context_lengths['plot_points']} å­—ç¬¦")
                logger.info(f"  - è®°å¿†æ€»é•¿åº¦: {total_memory_length} å­—ç¬¦")
                logger.info(f"  - å‰ç½®ç« èŠ‚ä¸Šä¸‹æ–‡é•¿åº¦: {len(previous_content)} å­—ç¬¦")
                logger.info(f"  - æ€»ä¸Šä¸‹æ–‡é•¿åº¦(ä¼°ç®—): {total_memory_length + len(previous_content) + 2000} å­—ç¬¦")
            
                # å‘é€å¼€å§‹äº‹ä»¶
                yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹AIåˆ›ä½œ...'}, ensure_ascii=False)}\n\n"
                
                # æ ¹æ®æ˜¯å¦æœ‰å‰ç½®å†…å®¹é€‰æ‹©ä¸åŒçš„æç¤ºè¯ï¼Œå¹¶åº”ç”¨å†™ä½œé£æ ¼å’Œè®°å¿†å¢å¼º
                if previous_content:
                    prompt = prompt_service.get_chapter_generation_with_context_prompt(
                        title=project.title,
                        theme=project.theme or '',
                        genre=project.genre or '',
                        narrative_perspective=project.narrative_perspective or 'ç¬¬ä¸‰äººç§°',
                        time_period=project.world_time_period or 'æœªè®¾å®š',
                        location=project.world_location or 'æœªè®¾å®š',
                        atmosphere=project.world_atmosphere or 'æœªè®¾å®š',
                        rules=project.world_rules or 'æœªè®¾å®š',
                        characters_info=characters_info or 'æš‚æ— è§’è‰²ä¿¡æ¯',
                        outlines_context=outlines_context,
                        previous_content=previous_content,
                        chapter_number=current_chapter.chapter_number,
                        chapter_title=current_chapter.title,
                        chapter_outline=outline.content if outline else current_chapter.summary or 'æš‚æ— å¤§çº²',
                        style_content=style_content,
                        target_word_count=target_word_count,
                        memory_context=memory_context
                    )
                else:
                    prompt = prompt_service.get_chapter_generation_prompt(
                        title=project.title,
                        theme=project.theme or '',
                        genre=project.genre or '',
                        narrative_perspective=project.narrative_perspective or 'ç¬¬ä¸‰äººç§°',
                        time_period=project.world_time_period or 'æœªè®¾å®š',
                        location=project.world_location or 'æœªè®¾å®š',
                        atmosphere=project.world_atmosphere or 'æœªè®¾å®š',
                        rules=project.world_rules or 'æœªè®¾å®š',
                        characters_info=characters_info or 'æš‚æ— è§’è‰²ä¿¡æ¯',
                        outlines_context=outlines_context,
                        chapter_number=current_chapter.chapter_number,
                        chapter_title=current_chapter.title,
                        chapter_outline=outline.content if outline else current_chapter.summary or 'æš‚æ— å¤§çº²',
                        style_content=style_content,
                        target_word_count=target_word_count,
                        memory_context=memory_context
                    )
                
                logger.info(f"å¼€å§‹AIæµå¼åˆ›ä½œç« èŠ‚ {chapter_id}")
                
                # æµå¼ç”Ÿæˆå†…å®¹
                full_content = ""
                async for chunk in user_ai_service.generate_text_stream(prompt=prompt):
                    full_content += chunk
                    yield f"data: {json.dumps({'type': 'content', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
                
                # æ›´æ–°ç« èŠ‚å†…å®¹åˆ°æ•°æ®åº“
                old_word_count = current_chapter.word_count or 0
                current_chapter.content = full_content
                new_word_count = len(full_content)
                current_chapter.word_count = new_word_count
                current_chapter.status = "completed"
                
                # æ›´æ–°é¡¹ç›®å­—æ•°
                project.current_words = project.current_words - old_word_count + new_word_count
                
                # è®°å½•ç”Ÿæˆå†å²
                history = GenerationHistory(
                    project_id=current_chapter.project_id,
                    chapter_id=current_chapter.id,
                    prompt=f"åˆ›ä½œç« èŠ‚: ç¬¬{current_chapter.chapter_number}ç«  {current_chapter.title}",
                    generated_content=full_content[:500] if len(full_content) > 500 else full_content,
                    model="default"
                )
                db_session.add(history)
                
                await db_session.commit()
                db_committed = True
                await db_session.refresh(current_chapter)
                
                logger.info(f"æˆåŠŸåˆ›ä½œç« èŠ‚ {chapter_id}ï¼Œå…± {new_word_count} å­—")
                
                # åˆ›å»ºåˆ†æä»»åŠ¡
                analysis_task = AnalysisTask(
                    chapter_id=chapter_id,
                    user_id=current_user_id,
                    project_id=project.id,
                    status='pending',
                    progress=0
                )
                db_session.add(analysis_task)
                await db_session.commit()
                await db_session.refresh(analysis_task)
                
                task_id = analysis_task.id
                logger.info(f"ğŸ“‹ å·²åˆ›å»ºåˆ†æä»»åŠ¡: {task_id}")
                
                # çŸ­æš‚å»¶è¿Ÿç¡®ä¿SQLite WALå®Œæˆå†™å…¥
                await asyncio.sleep(0.05)
                
                # ç›´æ¥å¯åŠ¨åå°åˆ†æï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
                background_tasks.add_task(
                    analyze_chapter_background,
                    chapter_id=chapter_id,
                    user_id=current_user_id,
                    project_id=project.id,
                    task_id=task_id,
                    ai_service=user_ai_service
                )
                
                # å‘é€å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«åˆ†æä»»åŠ¡IDï¼‰
                completion_data = {
                    'type': 'done',
                    'message': 'åˆ›ä½œå®Œæˆ',
                    'word_count': new_word_count,
                    'analysis_task_id': task_id
                }
                yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                
                # å‘é€åˆ†æå¼€å§‹äº‹ä»¶
                analysis_started_data = {
                    'type': 'analysis_started',
                    'task_id': task_id,
                    'message': 'ç« èŠ‚åˆ†æå·²å¼€å§‹'
                }
                yield f"data: {json.dumps(analysis_started_data, ensure_ascii=False)}\n\n"
                
                break  # é€€å‡ºasync for db_sessionå¾ªç¯
        
        except GeneratorExit:
            # SSEè¿æ¥æ–­å¼€
            logger.warning("ç« èŠ‚ç”Ÿæˆå™¨è¢«æå‰å…³é—­ï¼ˆSSEæ–­å¼€ï¼‰")
            if db_session and not db_committed:
                try:
                    if db_session.in_transaction():
                        await db_session.rollback()
                        logger.info("ç« èŠ‚ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
                except Exception as e:
                    logger.error(f"GeneratorExitå›æ»šå¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"æµå¼åˆ›ä½œç« èŠ‚å¤±è´¥: {str(e)}")
            if db_session and not db_committed:
                try:
                    if db_session.in_transaction():
                        await db_session.rollback()
                        logger.info("ç« èŠ‚ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
                except Exception as rollback_error:
                    logger.error(f"å›æ»šå¤±è´¥: {str(rollback_error)}")
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
        finally:
            # ç¡®ä¿æ•°æ®åº“ä¼šè¯è¢«æ­£ç¡®å…³é—­
            if db_session:
                try:
                    # æœ€åæ£€æŸ¥ï¼šç¡®ä¿æ²¡æœ‰æœªæäº¤çš„äº‹åŠ¡
                    if not db_committed and db_session.in_transaction():
                        await db_session.rollback()
                        logger.warning("åœ¨finallyä¸­å‘ç°æœªæäº¤äº‹åŠ¡ï¼Œå·²å›æ»š")
                    
                    await db_session.close()
                    logger.info("æ•°æ®åº“ä¼šè¯å·²å…³é—­")
                except Exception as close_error:
                    logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯å¤±è´¥: {str(close_error)}")
                    # å¼ºåˆ¶å…³é—­
                    try:
                        await db_session.close()
                    except:
                        pass
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/{chapter_id}/analysis/status", summary="æŸ¥è¯¢ç« èŠ‚åˆ†æä»»åŠ¡çŠ¶æ€")
async def get_analysis_task_status(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    æŸ¥è¯¢æŒ‡å®šç« èŠ‚çš„æœ€æ–°åˆ†æä»»åŠ¡çŠ¶æ€
    
    è‡ªåŠ¨æ¢å¤æœºåˆ¶ï¼š
    - å¦‚æœä»»åŠ¡çŠ¶æ€ä¸ºrunningä¸”è¶…è¿‡1åˆ†é’Ÿæœªæ›´æ–°ï¼Œè‡ªåŠ¨æ ‡è®°ä¸ºfailed
    - å¦‚æœä»»åŠ¡çŠ¶æ€ä¸ºpendingä¸”è¶…è¿‡2åˆ†é’Ÿæœªå¯åŠ¨ï¼Œè‡ªåŠ¨æ ‡è®°ä¸ºfailed
    
    è¿”å›:
    - task_id: ä»»åŠ¡ID
    - status: pending/running/completed/failed
    - progress: 0-100
    - error_message: é”™è¯¯ä¿¡æ¯(å¦‚æœå¤±è´¥)
    - auto_recovered: æ˜¯å¦è¢«è‡ªåŠ¨æ¢å¤
    - created_at: åˆ›å»ºæ—¶é—´
    - completed_at: å®Œæˆæ—¶é—´
    """
    from datetime import timedelta
    
    # è·å–è¯¥ç« èŠ‚æœ€æ–°çš„åˆ†æä»»åŠ¡
    result = await db.execute(
        select(AnalysisTask)
        .where(AnalysisTask.chapter_id == chapter_id)
        .order_by(AnalysisTask.created_at.desc())
        .limit(1)
    )
    task = result.scalar_one_or_none()
    
    if not task:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°åˆ†æä»»åŠ¡")
    
    auto_recovered = False
    current_time = datetime.now()
    
    # è‡ªåŠ¨æ¢å¤å¡ä½çš„ä»»åŠ¡
    if task.status == 'running':
        # å¦‚æœä»»åŠ¡åœ¨runningçŠ¶æ€è¶…è¿‡1åˆ†é’Ÿï¼Œæ ‡è®°ä¸ºå¤±è´¥
        if task.started_at and (current_time - task.started_at) > timedelta(minutes=1):
            task.status = 'failed'
            task.error_message = 'ä»»åŠ¡è¶…æ—¶ï¼ˆè¶…è¿‡1åˆ†é’Ÿæœªå®Œæˆï¼Œå·²è‡ªåŠ¨æ¢å¤ï¼‰'
            task.completed_at = current_time
            task.progress = 0
            auto_recovered = True
            await db.commit()
            await db.refresh(task)
            logger.warning(f"ğŸ”„ è‡ªåŠ¨æ¢å¤å¡ä½çš„ä»»åŠ¡: {task.id}, ç« èŠ‚: {chapter_id}")
    
    elif task.status == 'pending':
        # å¦‚æœä»»åŠ¡åœ¨pendingçŠ¶æ€è¶…è¿‡2åˆ†é’Ÿä»æœªå¼€å§‹ï¼Œæ ‡è®°ä¸ºå¤±è´¥
        if task.created_at and (current_time - task.created_at) > timedelta(minutes=2):
            task.status = 'failed'
            task.error_message = 'ä»»åŠ¡å¯åŠ¨è¶…æ—¶ï¼ˆè¶…è¿‡2åˆ†é’Ÿæœªå¯åŠ¨ï¼Œå·²è‡ªåŠ¨æ¢å¤ï¼‰'
            task.completed_at = current_time
            task.progress = 0
            auto_recovered = True
            await db.commit()
            await db.refresh(task)
            logger.warning(f"ğŸ”„ è‡ªåŠ¨æ¢å¤æœªå¯åŠ¨çš„ä»»åŠ¡: {task.id}, ç« èŠ‚: {chapter_id}")
    
    return {
        "task_id": task.id,
        "chapter_id": task.chapter_id,
        "status": task.status,
        "progress": task.progress,
        "error_message": task.error_message,
        "auto_recovered": auto_recovered,
        "created_at": task.created_at.isoformat() if task.created_at else None,
        "started_at": task.started_at.isoformat() if task.started_at else None,
        "completed_at": task.completed_at.isoformat() if task.completed_at else None
    }


@router.get("/{chapter_id}/analysis", summary="è·å–ç« èŠ‚åˆ†æç»“æœ")
async def get_chapter_analysis(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„å®Œæ•´åˆ†æç»“æœ
    
    è¿”å›:
    - analysis_data: å®Œæ•´çš„åˆ†ææ•°æ®(JSON)
    - summary: åˆ†ææ‘˜è¦æ–‡æœ¬
    - memories: æå–çš„è®°å¿†åˆ—è¡¨
    - created_at: åˆ†ææ—¶é—´
    """
    # è·å–åˆ†æç»“æœ
    analysis_result = await db.execute(
        select(PlotAnalysis)
        .where(PlotAnalysis.chapter_id == chapter_id)
        .order_by(PlotAnalysis.created_at.desc())
        .limit(1)
    )
    analysis = analysis_result.scalar_one_or_none()
    
    if not analysis:
        raise HTTPException(status_code=404, detail="è¯¥ç« èŠ‚æš‚æ— åˆ†æç»“æœ")
    
    # è·å–ç›¸å…³è®°å¿†
    memories_result = await db.execute(
        select(StoryMemory)
        .where(StoryMemory.chapter_id == chapter_id)
        .order_by(StoryMemory.importance_score.desc())
    )
    memories = memories_result.scalars().all()
    
    return {
        "chapter_id": chapter_id,
        "analysis": analysis.to_dict(),  # ä½¿ç”¨to_dict()æ–¹æ³•
        "memories": [
            {
                "id": mem.id,
                "type": mem.memory_type,
                "title": mem.title,
                "content": mem.content,
                "importance": mem.importance_score,
                "tags": mem.tags,
                "is_foreshadow": mem.is_foreshadow,
                "position": mem.chapter_position,
                "related_characters": mem.related_characters
            }
            for mem in memories
        ],
        "created_at": analysis.created_at.isoformat() if analysis.created_at else None
    }


@router.get("/{chapter_id}/annotations", summary="è·å–ç« èŠ‚æ ‡æ³¨æ•°æ®")
async def get_chapter_annotations(
    chapter_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„æ ‡æ³¨æ•°æ®ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºæ ‡æ³¨ï¼‰
    
    è¿”å›æ ¼å¼åŒ–çš„æ ‡æ³¨åˆ—è¡¨ï¼ŒåŒ…å«ç²¾ç¡®ä½ç½®ä¿¡æ¯
    é€‚ç”¨äºç« èŠ‚å†…å®¹çš„å¯è§†åŒ–æ ‡æ³¨å±•ç¤º
    """
    # è·å–ç« èŠ‚
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # è·å–åˆ†æç»“æœ
    analysis_result = await db.execute(
        select(PlotAnalysis)
        .where(PlotAnalysis.chapter_id == chapter_id)
        .order_by(PlotAnalysis.created_at.desc())
        .limit(1)
    )
    analysis = analysis_result.scalar_one_or_none()
    
    # è·å–è®°å¿†
    memories_result = await db.execute(
        select(StoryMemory)
        .where(StoryMemory.chapter_id == chapter_id)
        .order_by(StoryMemory.importance_score.desc())
    )
    memories = memories_result.scalars().all()
    
    # æ„å»ºæ ‡æ³¨æ•°æ®
    annotations = []
    
    for mem in memories:
        # ä¼˜å…ˆä»æ•°æ®åº“è¯»å–ä½ç½®ä¿¡æ¯
        position = mem.chapter_position if mem.chapter_position is not None else -1
        length = mem.text_length if hasattr(mem, 'text_length') and mem.text_length is not None else 0
        metadata_extra = {}
        
        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ä½ç½®ä¿¡æ¯ï¼Œå°è¯•ä»åˆ†ææ•°æ®ä¸­é‡æ–°è®¡ç®—
        if position == -1 and analysis and chapter.content:
            # æ ¹æ®è®°å¿†ç±»å‹ä»åˆ†ææ•°æ®ä¸­æŸ¥æ‰¾å¯¹åº”é¡¹
            if mem.memory_type == 'hook' and analysis.hooks:
                for hook in analysis.hooks:
                    # é€šè¿‡æ ‡é¢˜æˆ–å†…å®¹åŒ¹é…
                    if mem.title and hook.get('type') in mem.title:
                        keyword = hook.get('keyword', '')
                        if keyword:
                            pos = chapter.content.find(keyword)
                            if pos != -1:
                                position = pos
                                length = len(keyword)
                        metadata_extra["strength"] = hook.get('strength', 5)
                        metadata_extra["position_desc"] = hook.get('position', '')
                        break
            
            elif mem.memory_type == 'foreshadow' and analysis.foreshadows:
                for foreshadow in analysis.foreshadows:
                    if foreshadow.get('content') in mem.content:
                        keyword = foreshadow.get('keyword', '')
                        if keyword:
                            pos = chapter.content.find(keyword)
                            if pos != -1:
                                position = pos
                                length = len(keyword)
                        metadata_extra["foreshadow_type"] = foreshadow.get('type', 'planted')
                        metadata_extra["strength"] = foreshadow.get('strength', 5)
                        break
            
            elif mem.memory_type == 'plot_point' and analysis.plot_points:
                for plot_point in analysis.plot_points:
                    if plot_point.get('content') in mem.content:
                        keyword = plot_point.get('keyword', '')
                        if keyword:
                            pos = chapter.content.find(keyword)
                            if pos != -1:
                                position = pos
                                length = len(keyword)
                        break
        else:
            # å¦‚æœæ•°æ®åº“æœ‰ä½ç½®ï¼Œä¹Ÿä»åˆ†ææ•°æ®ä¸­æå–é¢å¤–çš„å…ƒæ•°æ®
            if analysis:
                if mem.memory_type == 'hook' and analysis.hooks:
                    for hook in analysis.hooks:
                        if mem.title and hook.get('type') in mem.title:
                            metadata_extra["strength"] = hook.get('strength', 5)
                            metadata_extra["position_desc"] = hook.get('position', '')
                            break
                
                elif mem.memory_type == 'foreshadow' and analysis.foreshadows:
                    for foreshadow in analysis.foreshadows:
                        if foreshadow.get('content') in mem.content:
                            metadata_extra["foreshadow_type"] = foreshadow.get('type', 'planted')
                            metadata_extra["strength"] = foreshadow.get('strength', 5)
                            break
        
        annotation = {
            "id": mem.id,
            "type": mem.memory_type,
            "title": mem.title,
            "content": mem.content,
            "importance": mem.importance_score or 0.5,
            "position": position,
            "length": length,
            "tags": mem.tags or [],
            "metadata": {
                "is_foreshadow": mem.is_foreshadow,
                "related_characters": mem.related_characters or [],
                "related_locations": mem.related_locations or [],
                **metadata_extra
            }
        }
        
        annotations.append(annotation)
    
    return {
        "chapter_id": chapter_id,
        "chapter_number": chapter.chapter_number,
        "title": chapter.title,
        "word_count": chapter.word_count or 0,
        "annotations": annotations,
        "has_analysis": analysis is not None,
        "summary": {
            "total_annotations": len(annotations),
            "hooks": len([a for a in annotations if a["type"] == "hook"]),
            "foreshadows": len([a for a in annotations if a["type"] == "foreshadow"]),
            "plot_points": len([a for a in annotations if a["type"] == "plot_point"]),
            "character_events": len([a for a in annotations if a["type"] == "character_event"])
        }
    }


@router.post("/{chapter_id}/analyze", summary="æ‰‹åŠ¨è§¦å‘ç« èŠ‚åˆ†æ")
async def trigger_chapter_analysis(
    chapter_id: str,
    request: Request,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ‰‹åŠ¨è§¦å‘ç« èŠ‚åˆ†æ(ç”¨äºé‡æ–°åˆ†ææˆ–åˆ†ææ—§ç« èŠ‚)
    """
    # ä»è¯·æ±‚ä¸­è·å–ç”¨æˆ·ID
    user_id = getattr(request.state, "user_id", None)
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    # éªŒè¯ç« èŠ‚å­˜åœ¨
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    if not chapter.content or chapter.content.strip() == "":
        raise HTTPException(status_code=400, detail="ç« èŠ‚å†…å®¹ä¸ºç©ºï¼Œæ— æ³•åˆ†æ")
    
    # è·å–é¡¹ç›®ä¿¡æ¯
    project_result = await db.execute(
        select(Project).where(Project.id == chapter.project_id)
    )
    project = project_result.scalar_one_or_none()
    
    if not project:
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
    
    # åˆ›å»ºåˆ†æä»»åŠ¡
    analysis_task = AnalysisTask(
        chapter_id=chapter_id,
        user_id=user_id,
        project_id=project.id,
        status='pending',
        progress=0
    )
    db.add(analysis_task)
    await db.commit()
    
    task_id = analysis_task.id
    logger.info(f"ğŸ“‹ åˆ›å»ºåˆ†æä»»åŠ¡: {task_id}, ç« èŠ‚: {chapter_id}")
    
    # åˆ·æ–°æ•°æ®åº“ä¼šè¯ï¼Œç¡®ä¿å…¶ä»–ä¼šè¯å¯ä»¥çœ‹åˆ°æ–°ä»»åŠ¡
    await db.refresh(analysis_task)
    
    # çŸ­æš‚å»¶è¿Ÿç¡®ä¿SQLite WALå®Œæˆå†™å…¥ï¼ˆè®©å…¶ä»–ä¼šè¯å¯è§ï¼‰
    await asyncio.sleep(3)
    
    # ç›´æ¥å¯åŠ¨åå°åˆ†æï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
    background_tasks.add_task(
        analyze_chapter_background,
        chapter_id=chapter_id,
        user_id=user_id,
        project_id=project.id,
        task_id=task_id,
        ai_service=user_ai_service
    )
    
    return {
        "task_id": task_id,
        "chapter_id": chapter_id,
        "status": "pending",
        "message": "åˆ†æä»»åŠ¡å·²åˆ›å»ºå¹¶å¼€å§‹æ‰§è¡Œ"
    }
