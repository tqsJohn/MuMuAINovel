"""ç« èŠ‚é‡æ–°ç”ŸæˆæœåŠ¡"""
from typing import Dict, Any, AsyncGenerator, Optional, List
from app.services.ai_service import AIService
from app.services.prompt_service import prompt_service
from app.models.chapter import Chapter
from app.models.memory import PlotAnalysis
from app.schemas.regeneration import ChapterRegenerateRequest, PreserveElementsConfig
from app.logger import get_logger
import difflib

logger = get_logger(__name__)


class ChapterRegenerator:
    """ç« èŠ‚é‡æ–°ç”ŸæˆæœåŠ¡"""
    
    def __init__(self, ai_service: AIService):
        self.ai_service = ai_service
        logger.info("âœ… ChapterRegeneratoråˆå§‹åŒ–æˆåŠŸ")
    
    async def regenerate_with_feedback(
        self,
        chapter: Chapter,
        analysis: Optional[PlotAnalysis],
        regenerate_request: ChapterRegenerateRequest,
        project_context: Dict[str, Any]
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æ ¹æ®åé¦ˆé‡æ–°ç”Ÿæˆç« èŠ‚ï¼ˆæµå¼ï¼‰
        
        Args:
            chapter: åŸå§‹ç« èŠ‚å¯¹è±¡
            analysis: åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
            regenerate_request: é‡æ–°ç”Ÿæˆè¯·æ±‚å‚æ•°
            project_context: é¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆé¡¹ç›®ä¿¡æ¯ã€è§’è‰²ã€å¤§çº²ç­‰ï¼‰
        
        Yields:
            åŒ…å«ç±»å‹å’Œæ•°æ®çš„å­—å…¸: {'type': 'progress'/'chunk', 'data': ...}
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹é‡æ–°ç”Ÿæˆç« èŠ‚: ç¬¬{chapter.chapter_number}ç« ")
            
            # 1. æ„å»ºä¿®æ”¹æŒ‡ä»¤
            yield {'type': 'progress', 'progress': 5, 'message': 'æ­£åœ¨æ„å»ºä¿®æ”¹æŒ‡ä»¤...'}
            modification_instructions = self._build_modification_instructions(
                analysis=analysis,
                regenerate_request=regenerate_request
            )
            
            logger.info(f"ğŸ“ ä¿®æ”¹æŒ‡ä»¤æ„å»ºå®Œæˆï¼Œé•¿åº¦: {len(modification_instructions)}å­—ç¬¦")
            
            # 2. æ„å»ºå®Œæ•´æç¤ºè¯
            yield {'type': 'progress', 'progress': 10, 'message': 'æ­£åœ¨æ„å»ºç”Ÿæˆæç¤ºè¯...'}
            full_prompt = self._build_regeneration_prompt(
                chapter=chapter,
                modification_instructions=modification_instructions,
                project_context=project_context,
                regenerate_request=regenerate_request
            )
            
            logger.info(f"ğŸ¯ æç¤ºè¯æ„å»ºå®Œæˆï¼Œå¼€å§‹AIç”Ÿæˆ")
            yield {'type': 'progress', 'progress': 15, 'message': 'å¼€å§‹AIç”Ÿæˆå†…å®¹...'}
            
            # 3. æµå¼ç”Ÿæˆæ–°å†…å®¹ï¼ŒåŒæ—¶è·Ÿè¸ªè¿›åº¦
            target_word_count = regenerate_request.target_word_count
            accumulated_length = 0
            
            async for chunk in self.ai_service.generate_text_stream(
                prompt=full_prompt,
                temperature=0.7
            ):
                # å‘é€å†…å®¹å—
                yield {'type': 'chunk', 'content': chunk}
                
                # æ›´æ–°ç´¯ç§¯å­—æ•°å¹¶è®¡ç®—è¿›åº¦ï¼ˆ15%-95%ï¼‰
                accumulated_length += len(chunk)
                # è¿›åº¦ä»15%å¼€å§‹ï¼Œåˆ°95%ç»“æŸï¼Œä¸ºåå¤„ç†é¢„ç•™5%
                generation_progress = min(15 + (accumulated_length / target_word_count) * 80, 95)
                yield {'type': 'progress', 'progress': int(generation_progress), 'word_count': accumulated_length}
            
            logger.info(f"âœ… ç« èŠ‚é‡æ–°ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {accumulated_length} å­—")
            yield {'type': 'progress', 'progress': 100, 'message': 'ç”Ÿæˆå®Œæˆ'}
            
        except Exception as e:
            logger.error(f"âŒ é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            raise
    
    def _build_modification_instructions(
        self,
        analysis: Optional[PlotAnalysis],
        regenerate_request: ChapterRegenerateRequest
    ) -> str:
        """æ„å»ºä¿®æ”¹æŒ‡ä»¤"""
        
        instructions = []
        
        # æ ‡é¢˜
        instructions.append("# ç« èŠ‚ä¿®æ”¹æŒ‡ä»¤\n")
        
        # 1. æ¥è‡ªåˆ†æçš„å»ºè®®
        if (analysis and 
            regenerate_request.selected_suggestion_indices and 
            analysis.suggestions):
            
            instructions.append("## ğŸ“‹ éœ€è¦æ”¹è¿›çš„é—®é¢˜ï¼ˆæ¥è‡ªAIåˆ†æï¼‰ï¼š\n")
            for idx in regenerate_request.selected_suggestion_indices:
                if 0 <= idx < len(analysis.suggestions):
                    suggestion = analysis.suggestions[idx]
                    instructions.append(f"{idx + 1}. {suggestion}")
            instructions.append("")
        
        # 2. ç”¨æˆ·è‡ªå®šä¹‰æŒ‡ä»¤
        if regenerate_request.custom_instructions:
            instructions.append("## âœï¸ ç”¨æˆ·è‡ªå®šä¹‰ä¿®æ”¹è¦æ±‚ï¼š\n")
            instructions.append(regenerate_request.custom_instructions)
            instructions.append("")
        
        # 3. é‡ç‚¹ä¼˜åŒ–æ–¹å‘
        if regenerate_request.focus_areas:
            instructions.append("## ğŸ¯ é‡ç‚¹ä¼˜åŒ–æ–¹å‘ï¼š\n")
            focus_map = {
                "pacing": "èŠ‚å¥æŠŠæ§ - è°ƒæ•´å™äº‹é€Ÿåº¦ï¼Œé¿å…æ‹–æ²“æˆ–è¿‡å¿«",
                "emotion": "æƒ…æ„Ÿæ¸²æŸ“ - æ·±åŒ–äººç‰©æƒ…æ„Ÿè¡¨è¾¾ï¼Œå¢å¼ºæ„ŸæŸ“åŠ›",
                "description": "åœºæ™¯æå†™ - ä¸°å¯Œç¯å¢ƒç»†èŠ‚ï¼Œå¢å¼ºç”»é¢æ„Ÿ",
                "dialogue": "å¯¹è¯è´¨é‡ - è®©å¯¹è¯æ›´è‡ªç„¶çœŸå®ï¼Œæ¨åŠ¨å‰§æƒ…",
                "conflict": "å†²çªå¼ºåº¦ - å¼ºåŒ–çŸ›ç›¾å†²çªï¼Œæå‡æˆå‰§å¼ åŠ›"
            }
            
            for area in regenerate_request.focus_areas:
                if area in focus_map:
                    instructions.append(f"- {focus_map[area]}")
            instructions.append("")
        
        # 4. ä¿ç•™è¦æ±‚
        if regenerate_request.preserve_elements:
            preserve = regenerate_request.preserve_elements
            instructions.append("## ğŸ”’ å¿…é¡»ä¿ç•™çš„å…ƒç´ ï¼š\n")
            
            if preserve.preserve_structure:
                instructions.append("- ä¿æŒåŸç« èŠ‚çš„æ•´ä½“ç»“æ„å’Œæƒ…èŠ‚æ¡†æ¶")
            
            if preserve.preserve_dialogues:
                instructions.append("- å¿…é¡»ä¿ç•™ä»¥ä¸‹å…³é”®å¯¹è¯ï¼š")
                for dialogue in preserve.preserve_dialogues:
                    instructions.append(f"  * {dialogue}")
            
            if preserve.preserve_plot_points:
                instructions.append("- å¿…é¡»ä¿ç•™ä»¥ä¸‹å…³é”®æƒ…èŠ‚ç‚¹ï¼š")
                for plot in preserve.preserve_plot_points:
                    instructions.append(f"  * {plot}")
            
            if preserve.preserve_character_traits:
                instructions.append("- ä¿æŒæ‰€æœ‰è§’è‰²çš„æ€§æ ¼ç‰¹å¾å’Œè¡Œä¸ºæ¨¡å¼ä¸€è‡´")
            
            instructions.append("")
        
        return "\n".join(instructions)
    
    def _build_regeneration_prompt(
        self,
        chapter: Chapter,
        modification_instructions: str,
        project_context: Dict[str, Any],
        regenerate_request: ChapterRegenerateRequest
    ) -> str:
        """æ„å»ºå®Œæ•´çš„é‡æ–°ç”Ÿæˆæç¤ºè¯"""
        
        prompt_parts = []
        
        # ç³»ç»Ÿè§’è‰²
        prompt_parts.append("""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸“ä¸šå°è¯´ç¼–è¾‘å’Œä½œå®¶ã€‚ç°åœ¨éœ€è¦æ ¹æ®åé¦ˆæ„è§é‡æ–°åˆ›ä½œä¸€ä¸ªç« èŠ‚ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†ç†è§£åŸç« èŠ‚çš„å†…å®¹å’Œæ„å›¾
2. è®¤çœŸåˆ†ææ‰€æœ‰çš„ä¿®æ”¹è¦æ±‚
3. åœ¨ä¿æŒæ•…äº‹è¿è´¯æ€§çš„å‰æä¸‹ï¼Œåˆ›ä½œä¸€ä¸ªæ”¹è¿›åçš„æ–°ç‰ˆæœ¬
4. ç¡®ä¿æ–°ç‰ˆæœ¬åœ¨è‰ºæœ¯æ€§å’Œå¯è¯»æ€§ä¸Šéƒ½æœ‰æ˜æ˜¾æå‡

---
""")
        
        # åŸå§‹ç« èŠ‚ä¿¡æ¯
        prompt_parts.append(f"""## ğŸ“– åŸå§‹ç« èŠ‚ä¿¡æ¯

**ç« èŠ‚**ï¼šç¬¬{chapter.chapter_number}ç« 
**æ ‡é¢˜**ï¼š{chapter.title}
**å­—æ•°**ï¼š{chapter.word_count}å­—

**åŸå§‹å†…å®¹**ï¼š
{chapter.content}

---
""")
        
        # ä¿®æ”¹æŒ‡ä»¤
        prompt_parts.append(modification_instructions)
        prompt_parts.append("\n---\n")
        
        # é¡¹ç›®èƒŒæ™¯ä¿¡æ¯
        prompt_parts.append(f"""## ğŸŒ é¡¹ç›®èƒŒæ™¯ä¿¡æ¯

**å°è¯´æ ‡é¢˜**ï¼š{project_context.get('project_title', 'æœªçŸ¥')}
**é¢˜æ**ï¼š{project_context.get('genre', 'æœªè®¾å®š')}
**ä¸»é¢˜**ï¼š{project_context.get('theme', 'æœªè®¾å®š')}
**å™äº‹è§†è§’**ï¼š{project_context.get('narrative_perspective', 'ç¬¬ä¸‰äººç§°')}
**ä¸–ç•Œè§‚è®¾å®š**ï¼š
- æ—¶ä»£èƒŒæ™¯ï¼š{project_context.get('time_period', 'æœªè®¾å®š')}
- åœ°ç†ä½ç½®ï¼š{project_context.get('location', 'æœªè®¾å®š')}
- æ°›å›´åŸºè°ƒï¼š{project_context.get('atmosphere', 'æœªè®¾å®š')}

---
""")
        
        # è§’è‰²ä¿¡æ¯
        if project_context.get('characters_info'):
            prompt_parts.append(f"""## ğŸ‘¥ è§’è‰²ä¿¡æ¯

{project_context['characters_info']}

---
""")
        
        # ç« èŠ‚å¤§çº²
        if project_context.get('chapter_outline'):
            prompt_parts.append(f"""## ğŸ“ æœ¬ç« å¤§çº²

{project_context['chapter_outline']}

---
""")
        
        # å‰ç½®ç« èŠ‚ä¸Šä¸‹æ–‡
        if project_context.get('previous_context'):
            prompt_parts.append(f"""## ğŸ“š å‰ç½®ç« èŠ‚ä¸Šä¸‹æ–‡

{project_context['previous_context']}

---
""")
        
        # åˆ›ä½œè¦æ±‚
        prompt_parts.append(f"""## âœ¨ åˆ›ä½œè¦æ±‚

1. **è§£å†³é—®é¢˜**ï¼šé’ˆå¯¹ä¸Šè¿°ä¿®æ”¹æŒ‡ä»¤ä¸­æåˆ°çš„æ‰€æœ‰é—®é¢˜è¿›è¡Œæ”¹è¿›
2. **ä¿æŒè¿è´¯**ï¼šç¡®ä¿ä¸å‰åç« èŠ‚çš„æƒ…èŠ‚ã€äººç‰©ã€é£æ ¼ä¿æŒä¸€è‡´
3. **æå‡è´¨é‡**ï¼šåœ¨èŠ‚å¥ã€æƒ…æ„Ÿã€æå†™ç­‰æ–¹é¢æ˜æ˜¾ä¼˜äºåŸç‰ˆ
4. **ä¿ç•™ç²¾å**ï¼šä¿æŒåŸç« èŠ‚ä¸­ä¼˜ç§€çš„éƒ¨åˆ†å’Œå…³é”®æƒ…èŠ‚
5. **å­—æ•°æ§åˆ¶**ï¼šç›®æ ‡å­—æ•°çº¦{regenerate_request.target_word_count}å­—ï¼ˆå¯é€‚å½“æµ®åŠ¨Â±20%ï¼‰

---

## ğŸ¬ å¼€å§‹åˆ›ä½œ

è¯·ç°åœ¨å¼€å§‹åˆ›ä½œæ”¹è¿›åçš„æ–°ç‰ˆæœ¬ç« èŠ‚å†…å®¹ã€‚

**é‡è¦æç¤º**ï¼š
- ç›´æ¥è¾“å‡ºç« èŠ‚æ­£æ–‡å†…å®¹ï¼Œä»æ•…äº‹å†…å®¹å¼€å§‹å†™
- **ä¸è¦**è¾“å‡ºç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚"ç¬¬Xç« "ã€"ç¬¬Xç« ï¼šXXX"ç­‰ï¼‰
- **ä¸è¦**è¾“å‡ºä»»ä½•é¢å¤–çš„è¯´æ˜ã€æ³¨é‡Šæˆ–å…ƒæ•°æ®
- åªéœ€è¦çº¯ç²¹çš„æ•…äº‹æ­£æ–‡å†…å®¹

ç°åœ¨å¼€å§‹ï¼š
""")
        
        return "\n".join(prompt_parts)
    
    def calculate_content_diff(
        self,
        original_content: str,
        new_content: str
    ) -> Dict[str, Any]:
        """
        è®¡ç®—ä¸¤ä¸ªç‰ˆæœ¬çš„å·®å¼‚
        
        Returns:
            å·®å¼‚ç»Ÿè®¡ä¿¡æ¯
        """
        # åŸºæœ¬ç»Ÿè®¡
        diff_stats = {
            'original_length': len(original_content),
            'new_length': len(new_content),
            'length_change': len(new_content) - len(original_content),
            'length_change_percent': round((len(new_content) - len(original_content)) / len(original_content) * 100, 2) if len(original_content) > 0 else 0
        }
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, original_content, new_content).ratio()
        diff_stats['similarity'] = round(similarity * 100, 2)
        diff_stats['difference'] = round((1 - similarity) * 100, 2)
        
        # æ®µè½ç»Ÿè®¡
        original_paragraphs = [p for p in original_content.split('\n\n') if p.strip()]
        new_paragraphs = [p for p in new_content.split('\n\n') if p.strip()]
        diff_stats['original_paragraph_count'] = len(original_paragraphs)
        diff_stats['new_paragraph_count'] = len(new_paragraphs)
        
        return diff_stats


# å…¨å±€å®ä¾‹
_regenerator_instance = None

def get_chapter_regenerator(ai_service: AIService) -> ChapterRegenerator:
    """è·å–ç« èŠ‚é‡æ–°ç”Ÿæˆå™¨å®ä¾‹"""
    global _regenerator_instance
    if _regenerator_instance is None:
        _regenerator_instance = ChapterRegenerator(ai_service)
    return _regenerator_instance