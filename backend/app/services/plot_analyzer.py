"""å‰§æƒ…åˆ†ææœåŠ¡ - è‡ªåŠ¨åˆ†æç« èŠ‚çš„é’©å­ã€ä¼ç¬”ã€å†²çªç­‰å…ƒç´ """
from typing import Dict, Any, List, Optional
from app.services.ai_service import AIService
from app.logger import get_logger
import json
import re

logger = get_logger(__name__)


class PlotAnalyzer:
    """å‰§æƒ…åˆ†æå™¨ - ä½¿ç”¨AIåˆ†æç« èŠ‚å†…å®¹"""
    
    # AIåˆ†ææç¤ºè¯æ¨¡æ¿
    ANALYSIS_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°è¯´ç¼–è¾‘å’Œå‰§æƒ…åˆ†æå¸ˆã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹ç« èŠ‚å†…å®¹:

**ç« èŠ‚ä¿¡æ¯:**
- ç« èŠ‚: ç¬¬{chapter_number}ç« 
- æ ‡é¢˜: {title}
- å­—æ•°: {word_count}å­—

**ç« èŠ‚å†…å®¹:**
{content}

---

**åˆ†æä»»åŠ¡:**
è¯·ä»ä¸“ä¸šç¼–è¾‘çš„è§’åº¦,å…¨é¢åˆ†æè¿™ä¸€ç« èŠ‚:

### 1. å‰§æƒ…é’©å­ (Hooks) - å¸å¼•è¯»è€…çš„å…ƒç´ 
è¯†åˆ«èƒ½å¤Ÿå¸å¼•è¯»è€…ç»§ç»­é˜…è¯»çš„å…³é”®å…ƒç´ :
- **æ‚¬å¿µé’©å­**: æœªè§£ä¹‹è°œã€ç–‘é—®ã€è°œå›¢
- **æƒ…æ„Ÿé’©å­**: å¼•å‘å…±é¸£çš„æƒ…æ„Ÿç‚¹ã€è§¦åŠ¨å¿ƒå¼¦çš„æ—¶åˆ»
- **å†²çªé’©å­**: çŸ›ç›¾å¯¹æŠ—ã€ç´§å¼ å±€åŠ¿
- **è®¤çŸ¥é’©å­**: é¢ è¦†è®¤çŸ¥çš„ä¿¡æ¯ã€æƒŠäººçœŸç›¸

æ¯ä¸ªé’©å­éœ€è¦:
- ç±»å‹åˆ†ç±»
- å…·ä½“å†…å®¹æè¿°
- å¼ºåº¦è¯„åˆ†(1-10)
- å‡ºç°ä½ç½®(å¼€å¤´/ä¸­æ®µ/ç»“å°¾)
- **å…³é”®è¯**: ã€å¿…å¡«ã€‘ä»ç« èŠ‚åŸæ–‡ä¸­é€å­—å¤åˆ¶ä¸€æ®µå…³é”®æ–‡æœ¬(8-25å­—)ï¼Œå¿…é¡»æ˜¯åŸæ–‡ä¸­çœŸå®å­˜åœ¨çš„è¿ç»­æ–‡å­—ï¼Œç”¨äºåœ¨æ–‡æœ¬ä¸­ç²¾ç¡®å®šä½ã€‚ä¸è¦æ¦‚æ‹¬æˆ–æ”¹å†™ï¼Œå¿…é¡»åŸæ ·å¤åˆ¶ï¼

### 2. ä¼ç¬”åˆ†æ (Foreshadowing)
- **åŸ‹ä¸‹çš„æ–°ä¼ç¬”**: æè¿°å†…å®¹ã€é¢„æœŸä½œç”¨ã€éšè—ç¨‹åº¦(1-10)
- **å›æ”¶çš„æ—§ä¼ç¬”**: å‘¼åº”å“ªä¸€ç« ã€å›æ”¶æ•ˆæœè¯„åˆ†
- **ä¼ç¬”è´¨é‡**: å·§å¦™æ€§å’Œåˆç†æ€§è¯„ä¼°
- **å…³é”®è¯**: ã€å¿…å¡«ã€‘ä»ç« èŠ‚åŸæ–‡ä¸­é€å­—å¤åˆ¶ä¸€æ®µå…³é”®æ–‡æœ¬(8-25å­—)ï¼Œå¿…é¡»æ˜¯åŸæ–‡ä¸­çœŸå®å­˜åœ¨çš„è¿ç»­æ–‡å­—ï¼Œç”¨äºåœ¨æ–‡æœ¬ä¸­ç²¾ç¡®å®šä½ã€‚ä¸è¦æ¦‚æ‹¬æˆ–æ”¹å†™ï¼Œå¿…é¡»åŸæ ·å¤åˆ¶ï¼

### 3. å†²çªåˆ†æ (Conflict)
- å†²çªç±»å‹: äººä¸äºº/äººä¸å·±/äººä¸ç¯å¢ƒ/äººä¸ç¤¾ä¼š
- å†²çªå„æ–¹åŠå…¶ç«‹åœº
- å†²çªå¼ºåº¦è¯„åˆ†(1-10)
- å†²çªè§£å†³è¿›åº¦(0-100%)

### 4. æƒ…æ„Ÿæ›²çº¿ (Emotional Arc)
- ä¸»å¯¼æƒ…ç»ª: ç´§å¼ /æ¸©é¦¨/æ‚²ä¼¤/æ¿€æ˜‚/å¹³é™ç­‰
- æƒ…æ„Ÿå¼ºåº¦(1-10)
- æƒ…ç»ªå˜åŒ–è½¨è¿¹æè¿°

### 5. è§’è‰²çŠ¶æ€è¿½è¸ª (Character Development)
å¯¹æ¯ä¸ªå‡ºåœºè§’è‰²åˆ†æ:
- å¿ƒç†çŠ¶æ€å˜åŒ–(å‰â†’å)
- å…³ç³»å˜åŒ–
- å…³é”®è¡ŒåŠ¨å’Œå†³ç­–
- æˆé•¿æˆ–é€€æ­¥

### 6. å…³é”®æƒ…èŠ‚ç‚¹ (Plot Points)
åˆ—å‡º3-5ä¸ªæ ¸å¿ƒæƒ…èŠ‚ç‚¹:
- æƒ…èŠ‚å†…å®¹
- ç±»å‹(revelation/conflict/resolution/transition)
- é‡è¦æ€§(0.0-1.0)
- å¯¹æ•…äº‹çš„å½±å“
- **å…³é”®è¯**: ã€å¿…å¡«ã€‘ä»ç« èŠ‚åŸæ–‡ä¸­é€å­—å¤åˆ¶ä¸€æ®µå…³é”®æ–‡æœ¬(8-25å­—)ï¼Œå¿…é¡»æ˜¯åŸæ–‡ä¸­çœŸå®å­˜åœ¨çš„è¿ç»­æ–‡å­—ï¼Œç”¨äºåœ¨æ–‡æœ¬ä¸­ç²¾ç¡®å®šä½ã€‚ä¸è¦æ¦‚æ‹¬æˆ–æ”¹å†™ï¼Œå¿…é¡»åŸæ ·å¤åˆ¶ï¼

### 7. åœºæ™¯ä¸èŠ‚å¥
- ä¸»è¦åœºæ™¯
- å™äº‹èŠ‚å¥(å¿«/ä¸­/æ…¢)
- å¯¹è¯ä¸æå†™çš„æ¯”ä¾‹

### 8. è´¨é‡è¯„åˆ†
- èŠ‚å¥æŠŠæ§: 1-10åˆ†
- å¸å¼•åŠ›: 1-10åˆ†  
- è¿è´¯æ€§: 1-10åˆ†
- æ•´ä½“è´¨é‡: 1-10åˆ†

### 9. æ”¹è¿›å»ºè®®
æä¾›3-5æ¡å…·ä½“çš„æ”¹è¿›å»ºè®®

---

**è¾“å‡ºæ ¼å¼(çº¯JSON,ä¸è¦markdownæ ‡è®°):**

{{
  "hooks": [
    {{
      "type": "æ‚¬å¿µ",
      "content": "å…·ä½“æè¿°",
      "strength": 8,
      "position": "ä¸­æ®µ",
      "keyword": "å¿…é¡»ä»åŸæ–‡é€å­—å¤åˆ¶çš„æ–‡æœ¬ç‰‡æ®µ"
    }}
  ],
  "foreshadows": [
    {{
      "content": "ä¼ç¬”å†…å®¹",
      "type": "planted",
      "strength": 7,
      "subtlety": 8,
      "reference_chapter": null,
      "keyword": "å¿…é¡»ä»åŸæ–‡é€å­—å¤åˆ¶çš„æ–‡æœ¬ç‰‡æ®µ"
    }}
  ],
  "conflict": {{
    "types": ["äººä¸äºº", "äººä¸å·±"],
    "parties": ["ä¸»è§’-å¤ä»‡", "åæ´¾-ç»´æŠ¤ç°çŠ¶"],
    "level": 8,
    "description": "å†²çªæè¿°",
    "resolution_progress": 0.3
  }},
  "emotional_arc": {{
    "primary_emotion": "ç´§å¼ ",
    "intensity": 8,
    "curve": "å¹³é™â†’ç´§å¼ â†’é«˜æ½®â†’é‡Šæ”¾",
    "secondary_emotions": ["æœŸå¾…", "ç„¦è™‘"]
  }},
  "character_states": [
    {{
      "character_name": "å¼ ä¸‰",
      "state_before": "çŠ¹è±«",
      "state_after": "åšå®š",
      "psychological_change": "å¿ƒç†å˜åŒ–æè¿°",
      "key_event": "è§¦å‘äº‹ä»¶",
      "relationship_changes": {{"æå››": "å…³ç³»æ”¹å–„"}}
    }}
  ],
  "plot_points": [
    {{
      "content": "æƒ…èŠ‚ç‚¹æè¿°",
      "type": "revelation",
      "importance": 0.9,
      "impact": "æ¨åŠ¨æ•…äº‹å‘å±•",
      "keyword": "å¿…é¡»ä»åŸæ–‡é€å­—å¤åˆ¶çš„æ–‡æœ¬ç‰‡æ®µ"
    }}
  ],
  "scenes": [
    {{
      "location": "åœ°ç‚¹",
      "atmosphere": "æ°›å›´",
      "duration": "æ—¶é•¿ä¼°è®¡"
    }}
  ],
  "pacing": "varied",
  "dialogue_ratio": 0.4,
  "description_ratio": 0.3,
  "scores": {{
    "pacing": 8,
    "engagement": 9,
    "coherence": 8,
    "overall": 8.5
  }},
  "plot_stage": "å‘å±•",
  "suggestions": [
    "å…·ä½“å»ºè®®1",
    "å…·ä½“å»ºè®®2"
  ]
}}

**é‡è¦æç¤º:**
1. æ¯ä¸ªé’©å­ã€ä¼ç¬”ã€æƒ…èŠ‚ç‚¹çš„keywordå­—æ®µæ˜¯å¿…å¡«çš„ï¼Œä¸èƒ½ä¸ºç©º
2. keywordå¿…é¡»æ˜¯ä»ç« èŠ‚åŸæ–‡ä¸­é€å­—å¤åˆ¶çš„æ–‡æœ¬ï¼Œé•¿åº¦8-25å­—
3. keywordç”¨äºåœ¨å‰ç«¯æ ‡æ³¨æ–‡æœ¬ä½ç½®ï¼Œæ‰€ä»¥å¿…é¡»èƒ½åœ¨åŸæ–‡ä¸­ç²¾ç¡®æ‰¾åˆ°
4. ä¸è¦ä½¿ç”¨æ¦‚æ‹¬æ€§è¯­å¥æˆ–æ”¹å†™åçš„æ–‡å­—ä½œä¸ºkeyword

åªè¿”å›JSON,ä¸è¦å…¶ä»–è¯´æ˜ã€‚"""
    
    def __init__(self, ai_service: AIService):
        """
        åˆå§‹åŒ–å‰§æƒ…åˆ†æå™¨
        
        Args:
            ai_service: AIæœåŠ¡å®ä¾‹
        """
        self.ai_service = ai_service
        logger.info("âœ… PlotAnalyzeråˆå§‹åŒ–æˆåŠŸ")
    
    async def analyze_chapter(
        self,
        chapter_number: int,
        title: str,
        content: str,
        word_count: int
    ) -> Optional[Dict[str, Any]]:
        """
        åˆ†æå•ç« å†…å®¹
        
        Args:
            chapter_number: ç« èŠ‚å·
            title: ç« èŠ‚æ ‡é¢˜
            content: ç« èŠ‚å†…å®¹
            word_count: å­—æ•°
        
        Returns:
            åˆ†æç»“æœå­—å…¸,å¤±è´¥è¿”å›None
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹åˆ†æç¬¬{chapter_number}ç« : {title}")
            
            # å¦‚æœå†…å®¹è¿‡é•¿,æˆªå–å‰8000å­—(é¿å…è¶…token)
            analysis_content = content[:8000] if len(content) > 8000 else content
            
            # æ„å»ºæç¤ºè¯
            prompt = self.ANALYSIS_PROMPT.format(
                chapter_number=chapter_number,
                title=title,
                word_count=word_count,
                content=analysis_content
            )
            
            # è°ƒç”¨AIè¿›è¡Œåˆ†æ
            # æ³¨æ„ï¼šä¸æŒ‡å®šmax_tokensï¼Œä½¿ç”¨ç”¨æˆ·åœ¨è®¾ç½®ä¸­é…ç½®çš„å€¼
            logger.info(f"  è°ƒç”¨AIåˆ†æ(å†…å®¹é•¿åº¦: {len(analysis_content)}å­—)...")
            response = await self.ai_service.generate_text(
                prompt=prompt,
                temperature=0.3  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„JSONè¾“å‡º
            )
            
            # ğŸ” æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹AIè¿”å›çš„åŸå§‹å†…å®¹
            # logger.info(f"ğŸ” AIè¿”å›ç±»å‹: {type(response)}")
            # logger.info(f"ğŸ” AIè¿”å›å†…å®¹(å‰500å­—ç¬¦): {str(response)}")
            
            # ä»è¿”å›çš„å­—å…¸ä¸­æå–contentå­—æ®µ
            if isinstance(response, dict):
                response_text = response.get('content', '')
                if not response_text:
                    logger.error("âŒ AIè¿”å›çš„å­—å…¸ä¸­æ²¡æœ‰contentå­—æ®µæˆ–contentä¸ºç©º")
                    return None
            else:
                # å…¼å®¹æ—§çš„å­—ç¬¦ä¸²è¿”å›æ ¼å¼
                response_text = response
            
            # è§£æJSONç»“æœ
            analysis_result = self._parse_analysis_response(response_text)
            
            if analysis_result:
                logger.info(f"âœ… ç¬¬{chapter_number}ç« åˆ†æå®Œæˆ")
                logger.info(f"  - é’©å­: {len(analysis_result.get('hooks', []))}ä¸ª")
                logger.info(f"  - ä¼ç¬”: {len(analysis_result.get('foreshadows', []))}ä¸ª")
                logger.info(f"  - æƒ…èŠ‚ç‚¹: {len(analysis_result.get('plot_points', []))}ä¸ª")
                logger.info(f"  - æ•´ä½“è¯„åˆ†: {analysis_result.get('scores', {}).get('overall', 'N/A')}")
                return analysis_result
            else:
                logger.error(f"âŒ ç¬¬{chapter_number}ç« åˆ†æå¤±è´¥: JSONè§£æé”™è¯¯")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ç« èŠ‚åˆ†æå¼‚å¸¸: {str(e)}")
            return None
    
    def _parse_analysis_response(self, response: str) -> Optional[Dict[str, Any]]:
        """
        è§£æAIè¿”å›çš„åˆ†æç»“æœ
        
        Args:
            response: AIè¿”å›çš„æ–‡æœ¬
        
        Returns:
            è§£æåçš„å­—å…¸,å¤±è´¥è¿”å›None
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            cleaned = response.strip()
            
            # ç§»é™¤å¯èƒ½çš„markdownæ ‡è®°
            cleaned = re.sub(r'^```json\s*', '', cleaned)
            cleaned = re.sub(r'^```\s*', '', cleaned)
            cleaned = re.sub(r'\s*```$', '', cleaned)
            
            # å°è¯•è§£æJSON
            result = json.loads(cleaned)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ['hooks', 'plot_points', 'scores']
            for field in required_fields:
                if field not in result:
                    logger.warning(f"âš ï¸ åˆ†æç»“æœç¼ºå°‘å­—æ®µ: {field}")
                    result[field] = [] if field != 'scores' else {}
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            logger.error(f"  åŸå§‹å“åº”(å‰500å­—): {response[:500]}")
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    logger.info("âœ… é€šè¿‡æ­£åˆ™æå–æˆåŠŸè§£æJSON")
                    return result
                except:
                    pass
            
            return None
        except Exception as e:
            logger.error(f"âŒ è§£æå¼‚å¸¸: {str(e)}")
            return None
    
    def extract_memories_from_analysis(
        self,
        analysis: Dict[str, Any],
        chapter_id: str,
        chapter_number: int,
        chapter_content: str = "",
        chapter_title: str = ""
    ) -> List[Dict[str, Any]]:
        """
        ä»åˆ†æç»“æœä¸­æå–è®°å¿†ç‰‡æ®µ
        
        Args:
            analysis: åˆ†æç»“æœ
            chapter_id: ç« èŠ‚ID
            chapter_number: ç« èŠ‚å·
            chapter_content: ç« èŠ‚å®Œæ•´å†…å®¹(ç”¨äºè®¡ç®—ä½ç½®)
            chapter_title: ç« èŠ‚æ ‡é¢˜
        
        Returns:
            è®°å¿†ç‰‡æ®µåˆ—è¡¨
        """
        memories = []
        
        try:
            # ã€æ–°å¢ã€‘0. æå–ç« èŠ‚æ‘˜è¦ä½œä¸ºè®°å¿†ï¼ˆç”¨äºè¯­ä¹‰æ£€ç´¢ç›¸å…³ç« èŠ‚ï¼‰
            chapter_summary = ""
            
            # å°è¯•ä»åˆ†æç»“æœè·å–æ‘˜è¦
            if analysis.get('summary'):
                chapter_summary = analysis.get('summary')
            # æˆ–è€…ä»æƒ…èŠ‚ç‚¹ç»„åˆç”Ÿæˆæ‘˜è¦
            elif analysis.get('plot_points'):
                plot_summaries = [p.get('content', '') for p in analysis.get('plot_points', [])[:3]]
                chapter_summary = "ï¼›".join(plot_summaries)
            # æˆ–è€…ä½¿ç”¨å†…å®¹å‰300å­—
            elif chapter_content:
                chapter_summary = chapter_content[:300] + ("..." if len(chapter_content) > 300 else "")
            
            # å¦‚æœæœ‰æ‘˜è¦ï¼Œæ·»åŠ åˆ°è®°å¿†ä¸­
            if chapter_summary:
                memories.append({
                    'type': 'chapter_summary',
                    'content': chapter_summary,
                    'title': f"ç¬¬{chapter_number}ç« ã€Š{chapter_title}ã€‹æ‘˜è¦",
                    'metadata': {
                        'chapter_id': chapter_id,
                        'chapter_number': chapter_number,
                        'importance_score': 0.6,  # ä¸­ç­‰é‡è¦æ€§
                        'tags': ['æ‘˜è¦', 'ç« èŠ‚æ¦‚è§ˆ', chapter_title],
                        'is_foreshadow': 0,
                        'text_position': 0,
                        'text_length': len(chapter_summary)
                    }
                })
                logger.info(f"  âœ… æ·»åŠ ç« èŠ‚æ‘˜è¦è®°å¿†: {len(chapter_summary)}å­—")
            
            # 1. æå–é’©å­ä½œä¸ºè®°å¿†
            for i, hook in enumerate(analysis.get('hooks', [])):
                if hook.get('strength', 0) >= 6:  # åªä¿å­˜å¼ºåº¦>=6çš„é’©å­
                    keyword = hook.get('keyword', '')
                    position, length = self._find_text_position(chapter_content, keyword)
                    
                    logger.info(f"  é’©å­ä½ç½®: keyword='{keyword[:30]}...', pos={position}, len={length}")
                    
                    memories.append({
                        'type': 'hook',
                        'content': f"[{hook.get('type', 'æœªçŸ¥')}é’©å­] {hook.get('content', '')}",
                        'title': f"{hook.get('type', 'é’©å­')} - {hook.get('position', '')}",
                        'metadata': {
                            'chapter_id': chapter_id,
                            'chapter_number': chapter_number,
                            'importance_score': min(hook.get('strength', 5) / 10, 1.0),
                            'tags': [hook.get('type', 'é’©å­'), hook.get('position', '')],
                            'is_foreshadow': 0,
                            'keyword': keyword,
                            'text_position': position,
                            'text_length': length,
                            'strength': hook.get('strength', 5),
                            'position_desc': hook.get('position', '')
                        }
                    })
            
            # 2. æå–ä¼ç¬”ä½œä¸ºè®°å¿†
            for i, foreshadow in enumerate(analysis.get('foreshadows', [])):
                is_planted = foreshadow.get('type') == 'planted'
                keyword = foreshadow.get('keyword', '')
                position, length = self._find_text_position(chapter_content, keyword)
                
                logger.info(f"  ä¼ç¬”ä½ç½®: keyword='{keyword[:30]}...', pos={position}, len={length}")
                
                memories.append({
                    'type': 'foreshadow',
                    'content': foreshadow.get('content', ''),
                    'title': f"{'åŸ‹ä¸‹ä¼ç¬”' if is_planted else 'å›æ”¶ä¼ç¬”'}",
                    'metadata': {
                        'chapter_id': chapter_id,
                        'chapter_number': chapter_number,
                        'importance_score': min(foreshadow.get('strength', 5) / 10, 1.0),
                        'tags': ['ä¼ç¬”', foreshadow.get('type', 'planted')],
                        'is_foreshadow': 1 if is_planted else 2,
                        'reference_chapter': foreshadow.get('reference_chapter'),
                        'keyword': keyword,
                        'text_position': position,
                        'text_length': length,
                        'foreshadow_type': foreshadow.get('type', 'planted'),
                        'strength': foreshadow.get('strength', 5)
                    }
                })
            
            # 3. æå–å…³é”®æƒ…èŠ‚ç‚¹
            for i, plot_point in enumerate(analysis.get('plot_points', [])):
                if plot_point.get('importance', 0) >= 0.6:  # åªä¿å­˜é‡è¦æ€§>=0.6çš„æƒ…èŠ‚ç‚¹
                    keyword = plot_point.get('keyword', '')
                    position, length = self._find_text_position(chapter_content, keyword)
                    
                    logger.info(f"  æƒ…èŠ‚ç‚¹ä½ç½®: keyword='{keyword[:30]}...', pos={position}, len={length}")
                    
                    memories.append({
                        'type': 'plot_point',
                        'content': f"{plot_point.get('content', '')}ã€‚å½±å“: {plot_point.get('impact', '')}",
                        'title': f"æƒ…èŠ‚ç‚¹ - {plot_point.get('type', 'æœªçŸ¥')}",
                        'metadata': {
                            'chapter_id': chapter_id,
                            'chapter_number': chapter_number,
                            'importance_score': plot_point.get('importance', 0.5),
                            'tags': ['æƒ…èŠ‚ç‚¹', plot_point.get('type', 'æœªçŸ¥')],
                            'is_foreshadow': 0,
                            'keyword': keyword,
                            'text_position': position,
                            'text_length': length
                        }
                    })
            
            # 4. æå–è§’è‰²çŠ¶æ€å˜åŒ–
            for i, char_state in enumerate(analysis.get('character_states', [])):
                char_name = char_state.get('character_name', 'æœªçŸ¥è§’è‰²')
                memories.append({
                    'type': 'character_event',
                    'content': f"{char_name}çš„çŠ¶æ€å˜åŒ–: {char_state.get('state_before', '')} â†’ {char_state.get('state_after', '')}ã€‚{char_state.get('psychological_change', '')}",
                    'title': f"{char_name}çš„å˜åŒ–",
                    'metadata': {
                        'chapter_id': chapter_id,
                        'chapter_number': chapter_number,
                        'importance_score': 0.7,
                        'tags': ['è§’è‰²', char_name, 'çŠ¶æ€å˜åŒ–'],
                        'related_characters': [char_name],
                        'is_foreshadow': 0
                    }
                })
            
            # 5. å¦‚æœæœ‰é‡è¦å†²çª,ä¹Ÿè®°å½•ä¸‹æ¥
            conflict = analysis.get('conflict', {})
            
            if conflict and conflict.get('level', 0) >= 7:
                # ç¡®ä¿ parties å’Œ types éƒ½æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
                parties = conflict.get('parties', [])
                if parties and isinstance(parties, list):
                    parties = [str(p) for p in parties]
                
                types = conflict.get('types', [])
                if types and isinstance(types, list):
                    types = [str(t) for t in types]
                
                memories.append({
                    'type': 'plot_point',
                    'content': f"é‡è¦å†²çª: {conflict.get('description', '')}ã€‚å†²çªå„æ–¹: {', '.join(parties)}",
                    'title': f"å†²çª - å¼ºåº¦{conflict.get('level', 0)}",
                    'metadata': {
                        'chapter_id': chapter_id,
                        'chapter_number': chapter_number,
                        'importance_score': min(conflict.get('level', 5) / 10, 1.0),
                        'tags': ['å†²çª'] + types,
                        'is_foreshadow': 0
                    }
                })
            
            logger.info(f"ğŸ“ ä»åˆ†æä¸­æå–äº†{len(memories)}æ¡è®°å¿†")
            return memories
            
        except Exception as e:
            logger.error(f"âŒ æå–è®°å¿†å¤±è´¥: {str(e)}")
            return []
    
    def _find_text_position(self, full_text: str, keyword: str) -> tuple[int, int]:
        """
        åœ¨å…¨æ–‡ä¸­æŸ¥æ‰¾å…³é”®è¯ä½ç½®
        
        Args:
            full_text: å®Œæ•´æ–‡æœ¬
            keyword: å…³é”®è¯
        
        Returns:
            (èµ·å§‹ä½ç½®, é•¿åº¦) å¦‚æœæœªæ‰¾åˆ°è¿”å›(-1, 0)
        """
        if not keyword or not full_text:
            return (-1, 0)
        
        try:
            # 1. ç²¾ç¡®åŒ¹é…
            pos = full_text.find(keyword)
            if pos != -1:
                return (pos, len(keyword))
            
            # 2. å»é™¤æ ‡ç‚¹ç¬¦å·ååŒ¹é…
            import re
            clean_keyword = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€Šã€‹ã€ã€‘]', '', keyword)
            clean_text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€Šã€‹ã€ã€‘]', '', full_text)
            pos = clean_text.find(clean_keyword)
            
            if pos != -1:
                # åå‘æ˜ å°„åˆ°åŸæ–‡ä½ç½®ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                return (pos, len(clean_keyword))
            
            # 3. æ¨¡ç³ŠåŒ¹é…ï¼šæŸ¥æ‰¾å…³é”®è¯çš„å‰åŠéƒ¨åˆ†
            if len(keyword) > 10:
                partial = keyword[:min(15, len(keyword))]
                pos = full_text.find(partial)
                if pos != -1:
                    return (pos, len(partial))
            
            # 4. æœªæ‰¾åˆ°
            logger.debug(f"æœªæ‰¾åˆ°å…³é”®è¯ä½ç½®: {keyword[:30]}...")
            return (-1, 0)
            
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾ä½ç½®å¤±è´¥: {str(e)}")
            return (-1, 0)
    
    def generate_analysis_summary(self, analysis: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆåˆ†ææ‘˜è¦æ–‡æœ¬
        
        Args:
            analysis: åˆ†æç»“æœ
        
        Returns:
            æ ¼å¼åŒ–çš„æ‘˜è¦æ–‡æœ¬
        """
        try:
            lines = ["=== ç« èŠ‚åˆ†ææŠ¥å‘Š ===\n"]
            
            # æ•´ä½“è¯„åˆ†
            scores = analysis.get('scores', {})
            lines.append(f"ã€æ•´ä½“è¯„åˆ†ã€‘")
            lines.append(f"  æ•´ä½“è´¨é‡: {scores.get('overall', 'N/A')}/10")
            lines.append(f"  èŠ‚å¥æŠŠæ§: {scores.get('pacing', 'N/A')}/10")
            lines.append(f"  å¸å¼•åŠ›: {scores.get('engagement', 'N/A')}/10")
            lines.append(f"  è¿è´¯æ€§: {scores.get('coherence', 'N/A')}/10\n")
            
            # å‰§æƒ…é˜¶æ®µ
            lines.append(f"ã€å‰§æƒ…é˜¶æ®µã€‘{analysis.get('plot_stage', 'æœªçŸ¥')}\n")
            
            # é’©å­ç»Ÿè®¡
            hooks = analysis.get('hooks', [])
            if hooks:
                lines.append(f"ã€é’©å­åˆ†æã€‘å…±{len(hooks)}ä¸ª")
                for hook in hooks[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    lines.append(f"  â€¢ [{hook.get('type')}] {hook.get('content', '')[:50]}... (å¼ºåº¦:{hook.get('strength', 0)})")
                lines.append("")
            
            # ä¼ç¬”ç»Ÿè®¡
            foreshadows = analysis.get('foreshadows', [])
            if foreshadows:
                planted = sum(1 for f in foreshadows if f.get('type') == 'planted')
                resolved = sum(1 for f in foreshadows if f.get('type') == 'resolved')
                lines.append(f"ã€ä¼ç¬”åˆ†æã€‘åŸ‹ä¸‹{planted}ä¸ª, å›æ”¶{resolved}ä¸ª\n")
            
            # å†²çªåˆ†æ
            conflict = analysis.get('conflict', {})
            if conflict:
                lines.append(f"ã€å†²çªåˆ†æã€‘")
                lines.append(f"  ç±»å‹: {', '.join(conflict.get('types', []))}")
                lines.append(f"  å¼ºåº¦: {conflict.get('level', 0)}/10")
                lines.append(f"  è¿›åº¦: {int(conflict.get('resolution_progress', 0) * 100)}%\n")
            
            # æ”¹è¿›å»ºè®®
            suggestions = analysis.get('suggestions', [])
            if suggestions:
                lines.append(f"ã€æ”¹è¿›å»ºè®®ã€‘")
                for i, sug in enumerate(suggestions, 1):
                    lines.append(f"  {i}. {sug}")
            
            return "\n".join(lines)
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}")
            return "åˆ†ææ‘˜è¦ç”Ÿæˆå¤±è´¥"


# åˆ›å»ºå…¨å±€å®ä¾‹(éœ€è¦æ—¶æ‰‹åŠ¨åˆå§‹åŒ–)
_plot_analyzer_instance = None

def get_plot_analyzer(ai_service: AIService) -> PlotAnalyzer:
    """è·å–å‰§æƒ…åˆ†æå™¨å®ä¾‹"""
    global _plot_analyzer_instance
    if _plot_analyzer_instance is None:
        _plot_analyzer_instance = PlotAnalyzer(ai_service)
    return _plot_analyzer_instance