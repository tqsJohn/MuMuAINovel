#!/usr/bin/env python3
"""
SQLite to PostgreSQL æ•°æ®è¿ç§»è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python backend/scripts/migrate_sqlite_to_postgres.py

å‰ç½®æ¡ä»¶:
    1. PostgreSQLæ•°æ®åº“å·²åˆ›å»º
    2. .envæ–‡ä»¶ä¸­DATABASE_URLå·²é…ç½®ä¸ºPostgreSQL
    3. SQLiteæ•°æ®æ–‡ä»¶å­˜åœ¨äº backend/data/ ç›®å½•
"""
import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Any
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import create_engine, text, select
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from app.database import Base
from app.models import (
    Project, Outline, Character, Chapter, GenerationHistory,
    Settings, WritingStyle, ProjectDefaultStyle,
    RelationshipType, CharacterRelationship, Organization, OrganizationMember,
    StoryMemory, PlotAnalysis, AnalysisTask, BatchGenerationTask,
    MCPPlugin
)
from app.config import settings

# åˆ›å»ºæ—¥å¿—ç›®å½•
log_dir = Path(__file__).parent.parent / "logs"
log_dir.mkdir(exist_ok=True)

# ç”Ÿæˆæ—¥å¿—æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
log_filename = log_dir / f"migration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

# è®¾ç½®æ—¥å¿— - åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # æ§åˆ¶å°è¾“å‡º
        logging.FileHandler(log_filename, encoding='utf-8')  # æ–‡ä»¶è¾“å‡º
    ]
)
logger = logging.getLogger(__name__)
logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_filename}")


class SQLiteToPostgresMigrator:
    """SQLiteåˆ°PostgreSQLçš„æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self, sqlite_dir: Path, target_user_id: str):
        """
        åˆå§‹åŒ–è¿ç§»å™¨
        
        Args:
            sqlite_dir: SQLiteæ•°æ®åº“æ–‡ä»¶ç›®å½•
            target_user_id: ç›®æ ‡ç”¨æˆ·IDï¼ˆè¿ç§»åçš„æ•°æ®å½’å±ï¼‰
        """
        self.sqlite_dir = sqlite_dir
        self.target_user_id = target_user_id
        self.sqlite_files = list(sqlite_dir.glob("ai_story_user_*.db"))
        
        # PostgreSQLè¿æ¥
        if "postgresql" not in settings.database_url:
            raise ValueError("DATABASE_URLå¿…é¡»é…ç½®ä¸ºPostgreSQL")
        
        self.pg_engine = create_async_engine(
            settings.database_url,
            echo=False,
            pool_pre_ping=True
        )
        
        self.pg_session_maker = async_sessionmaker(
            self.pg_engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
    
    async def migrate_all(self):
        """è¿ç§»æ‰€æœ‰SQLiteæ•°æ®åº“"""
        if not self.sqlite_files:
            logger.warning(f"æœªæ‰¾åˆ°SQLiteæ•°æ®åº“æ–‡ä»¶: {self.sqlite_dir}")
            return
        
        logger.info(f"æ‰¾åˆ° {len(self.sqlite_files)} ä¸ªSQLiteæ•°æ®åº“æ–‡ä»¶")
        
        # åˆ›å»ºPostgreSQLè¡¨ç»“æ„
        await self._create_tables()
        
        # åˆå§‹åŒ–å…³ç³»ç±»å‹æ•°æ®
        await self._init_relationship_types()
        
        # é€ä¸ªè¿ç§»
        for sqlite_file in self.sqlite_files:
            await self._migrate_single_db(sqlite_file)
        
        # é‡ç½®è‡ªå¢åºåˆ—
        await self._reset_sequences()
        
        logger.info("âœ… æ‰€æœ‰æ•°æ®è¿ç§»å®Œæˆ")
    
    async def _create_tables(self):
        """åˆ›å»ºPostgreSQLè¡¨ç»“æ„"""
        logger.info("åˆ›å»ºPostgreSQLè¡¨ç»“æ„...")
        async with self.pg_engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logger.info("âœ… è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")
    
    async def _init_relationship_types(self):
        """åˆå§‹åŒ–å…³ç³»ç±»å‹æ•°æ®"""
        logger.info("åˆå§‹åŒ–å…³ç³»ç±»å‹æ•°æ®...")
        
        # é¢„ç½®å…³ç³»ç±»å‹æ•°æ®
        relationship_types = [
            # å®¶æ—å…³ç³»
            {"name": "çˆ¶äº²", "category": "family", "reverse_name": "å­å¥³", "intimacy_range": "high", "icon": "ğŸ‘¨"},
            {"name": "æ¯äº²", "category": "family", "reverse_name": "å­å¥³", "intimacy_range": "high", "icon": "ğŸ‘©"},
            {"name": "å…„å¼Ÿ", "category": "family", "reverse_name": "å…„å¼Ÿ", "intimacy_range": "high", "icon": "ğŸ‘¬"},
            {"name": "å§å¦¹", "category": "family", "reverse_name": "å§å¦¹", "intimacy_range": "high", "icon": "ğŸ‘­"},
            {"name": "å­å¥³", "category": "family", "reverse_name": "çˆ¶æ¯", "intimacy_range": "high", "icon": "ğŸ‘¶"},
            {"name": "é…å¶", "category": "family", "reverse_name": "é…å¶", "intimacy_range": "high", "icon": "ğŸ’‘"},
            {"name": "æ‹äºº", "category": "family", "reverse_name": "æ‹äºº", "intimacy_range": "high", "icon": "ğŸ’•"},
            
            # ç¤¾äº¤å…³ç³»
            {"name": "å¸ˆçˆ¶", "category": "social", "reverse_name": "å¾’å¼Ÿ", "intimacy_range": "high", "icon": "ğŸ“"},
            {"name": "å¾’å¼Ÿ", "category": "social", "reverse_name": "å¸ˆçˆ¶", "intimacy_range": "high", "icon": "ğŸ“š"},
            {"name": "æœ‹å‹", "category": "social", "reverse_name": "æœ‹å‹", "intimacy_range": "medium", "icon": "ğŸ¤"},
            {"name": "åŒå­¦", "category": "social", "reverse_name": "åŒå­¦", "intimacy_range": "medium", "icon": "ğŸ’"},
            {"name": "é‚»å±…", "category": "social", "reverse_name": "é‚»å±…", "intimacy_range": "low", "icon": "ğŸ˜ï¸"},
            {"name": "çŸ¥å·±", "category": "social", "reverse_name": "çŸ¥å·±", "intimacy_range": "high", "icon": "ğŸ’™"},
            
            # èŒä¸šå…³ç³»
            {"name": "ä¸Šå¸", "category": "professional", "reverse_name": "ä¸‹å±", "intimacy_range": "low", "icon": "ğŸ‘”"},
            {"name": "ä¸‹å±", "category": "professional", "reverse_name": "ä¸Šå¸", "intimacy_range": "low", "icon": "ğŸ’¼"},
            {"name": "åŒäº‹", "category": "professional", "reverse_name": "åŒäº‹", "intimacy_range": "medium", "icon": "ğŸ¤µ"},
            {"name": "åˆä½œä¼™ä¼´", "category": "professional", "reverse_name": "åˆä½œä¼™ä¼´", "intimacy_range": "medium", "icon": "ğŸ¤œğŸ¤›"},
            
            # æ•Œå¯¹å…³ç³»
            {"name": "æ•Œäºº", "category": "hostile", "reverse_name": "æ•Œäºº", "intimacy_range": "low", "icon": "âš”ï¸"},
            {"name": "ä»‡äºº", "category": "hostile", "reverse_name": "ä»‡äºº", "intimacy_range": "low", "icon": "ğŸ’¢"},
            {"name": "ç«äº‰å¯¹æ‰‹", "category": "hostile", "reverse_name": "ç«äº‰å¯¹æ‰‹", "intimacy_range": "low", "icon": "ğŸ¯"},
            {"name": "å®¿æ•Œ", "category": "hostile", "reverse_name": "å®¿æ•Œ", "intimacy_range": "low", "icon": "âš¡"},
        ]
        
        try:
            async with self.pg_session_maker() as session:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ•°æ®
                result = await session.execute(select(RelationshipType))
                existing = result.scalars().first()
                
                if existing:
                    logger.info("å…³ç³»ç±»å‹æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
                    return
                
                # æ’å…¥é¢„ç½®æ•°æ®
                logger.info("å¼€å§‹æ’å…¥å…³ç³»ç±»å‹æ•°æ®...")
                for rt_data in relationship_types:
                    relationship_type = RelationshipType(**rt_data)
                    session.add(relationship_type)
                
                await session.commit()
                logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(relationship_types)} æ¡å…³ç³»ç±»å‹æ•°æ®")
                
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å…³ç³»ç±»å‹æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­è¿ç§»æµç¨‹
            logger.warning("å…³ç³»ç±»å‹åˆå§‹åŒ–å¤±è´¥ï¼Œå°†è·³è¿‡æœ‰å¤–é”®ä¾èµ–çš„è®°å½•")
    
    async def _migrate_single_db(self, sqlite_file: Path):
        """è¿ç§»å•ä¸ªSQLiteæ•°æ®åº“"""
        # ä»æ–‡ä»¶åæå–user_id
        filename = sqlite_file.stem  # ai_story_user_xxx
        if filename.startswith("ai_story_user_"):
            user_id = filename.replace("ai_story_user_", "")
        else:
            user_id = self.target_user_id
        
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹è¿ç§»: {sqlite_file.name} -> user_id: {user_id}")
        logger.info(f"{'='*60}")
        
        # åˆ›å»ºSQLiteè¿æ¥
        sqlite_url = f"sqlite+aiosqlite:///{sqlite_file.absolute()}"
        sqlite_engine = create_async_engine(sqlite_url, echo=False)
        sqlite_session_maker = async_sessionmaker(
            sqlite_engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
        
        try:
            # è¿ç§»å„ä¸ªè¡¨
            async with sqlite_session_maker() as sqlite_session:
                async with self.pg_session_maker() as pg_session:
                    # æŒ‰ç…§ä¾èµ–é¡ºåºè¿ç§»
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, Settings, "è®¾ç½®"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, Project, "é¡¹ç›®"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, Character, "è§’è‰²"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, Outline, "å¤§çº²"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, Chapter, "ç« èŠ‚"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, CharacterRelationship, "è§’è‰²å…³ç³»"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, Organization, "ç»„ç»‡"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, OrganizationMember, "ç»„ç»‡æˆå‘˜"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, GenerationHistory, "ç”Ÿæˆå†å²"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, WritingStyle, "å†™ä½œé£æ ¼"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, ProjectDefaultStyle, "é¡¹ç›®é»˜è®¤é£æ ¼"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, StoryMemory, "è®°å¿†"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, PlotAnalysis, "å‰§æƒ…åˆ†æ"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, AnalysisTask, "åˆ†æä»»åŠ¡"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, BatchGenerationTask, "æ‰¹é‡ç”Ÿæˆä»»åŠ¡"
                    )
                    await self._migrate_table(
                        sqlite_session, pg_session, user_id, MCPPlugin, "MCPæ’ä»¶"
                    )
                    
                    await pg_session.commit()
            
            logger.info(f"âœ… {sqlite_file.name} è¿ç§»å®Œæˆ")
        
        except Exception as e:
            logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}", exc_info=True)
        finally:
            await sqlite_engine.dispose()
    
    async def _migrate_table(
        self,
        sqlite_session: AsyncSession,
        pg_session: AsyncSession,
        user_id: str,
        model_class,
        table_name: str
    ):
        """è¿ç§»å•ä¸ªè¡¨çš„æ•°æ®"""
        try:
            # è·å–SQLiteè¡¨ä¸­å®é™…å­˜åœ¨çš„åˆ—
            sqlite_table = model_class.__table__
            sqlite_conn = await sqlite_session.connection()
            
            # æŸ¥è¯¢SQLiteè¡¨ç»“æ„
            inspect_result = await sqlite_conn.execute(
                text(f"PRAGMA table_info({sqlite_table.name})")
            )
            sqlite_columns = {row[1] for row in inspect_result.fetchall()}  # row[1]æ˜¯åˆ—å
            
            # æ„å»ºåªåŒ…å«SQLiteä¸­å­˜åœ¨çš„åˆ—çš„æŸ¥è¯¢
            available_columns = [
                c for c in model_class.__table__.columns
                if c.name in sqlite_columns
            ]
            
            if not available_columns:
                logger.warning(f"  âš ï¸ {table_name}: è¡¨ç»“æ„ä¸åŒ¹é…ï¼Œè·³è¿‡")
                return
            
            # ä»SQLiteè¯»å–æ•°æ®ï¼ˆåªæŸ¥è¯¢å­˜åœ¨çš„åˆ—ï¼‰
            result = await sqlite_session.execute(
                select(*available_columns)
            )
            records = result.all()
            
            if not records:
                logger.info(f"  - {table_name}: æ— æ•°æ®")
                return
            
            # ä¸ºæ¯æ¡è®°å½•åˆ›å»ºå­—å…¸å¹¶æ·»åŠ user_id
            migrated_count = 0
            skipped_count = 0
            
            for record in records:
                # ä»æŸ¥è¯¢ç»“æœæ„å»ºå­—å…¸
                record_dict = {}
                for i, col in enumerate(available_columns):
                    record_dict[col.name] = record[i]
                
                # æ·»åŠ user_idï¼ˆå¦‚æœPostgreSQLæ¨¡å‹æœ‰è¿™ä¸ªå­—æ®µä½†SQLiteæ²¡æœ‰ï¼‰
                if hasattr(model_class, 'user_id') and 'user_id' not in record_dict:
                    record_dict['user_id'] = user_id
                
                # éªŒè¯å­—æ®µé•¿åº¦ï¼ˆé˜²æ­¢è¶…é•¿å­—æ®µå¯¼è‡´æ’å…¥å¤±è´¥ï¼‰
                if not self._validate_field_lengths(model_class, record_dict, table_name):
                    skipped_count += 1
                    record_id = record_dict.get('id', 'unknown')
                    logger.warning(f"    âš ï¸ [{table_name}] è·³è¿‡è¶…é•¿å­—æ®µè®°å½• ID={record_id}")
                    continue
                
                # éªŒè¯å¤–é”®å¼•ç”¨ï¼ˆé’ˆå¯¹æœ‰å¤–é”®çš„è¡¨ï¼‰
                validation_result = await self._validate_foreign_keys(pg_session, model_class, record_dict)
                if not validation_result:
                    skipped_count += 1
                    record_id = record_dict.get('id', 'unknown')
                    logger.warning(f"    âš ï¸ [{table_name}] è·³è¿‡æ— æ•ˆå¤–é”®è®°å½• ID={record_id}")
                    # è¾“å‡ºè®°å½•è¯¦æƒ…ä»¥ä¾¿è°ƒè¯•
                    if model_class.__tablename__ == 'story_memories':
                        logger.warning(f"       è®°å¿†è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                     f"chapter_id={record_dict.get('chapter_id')}, "
                                     f"type={record_dict.get('memory_type')}")
                    elif model_class.__tablename__ == 'character_relationships':
                        logger.warning(f"       å…³ç³»è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                     f"from={record_dict.get('character_from_id')}, "
                                     f"to={record_dict.get('character_to_id')}, "
                                     f"type_id={record_dict.get('relationship_type_id')}")
                    elif model_class.__tablename__ == 'organizations':
                        logger.warning(f"       ç»„ç»‡è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                     f"character_id={record_dict.get('character_id')}")
                    elif model_class.__tablename__ == 'organization_members':
                        logger.warning(f"       æˆå‘˜è¯¦æƒ…: org_id={record_dict.get('organization_id')}, "
                                     f"character_id={record_dict.get('character_id')}")
                    elif model_class.__tablename__ == 'writing_styles':
                        logger.warning(f"       å†™ä½œé£æ ¼è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"name={record_dict.get('name')}, "
                                        f"style_type={record_dict.get('style_type')}")
                    elif model_class.__tablename__ == 'characters':
                        logger.warning(f"       è§’è‰²è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"name={record_dict.get('name')}, "
                                        f"is_organization={record_dict.get('is_organization')}")
                    elif model_class.__tablename__ == 'outlines':
                        logger.warning(f"       å¤§çº²è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"title={record_dict.get('title')}")
                    elif model_class.__tablename__ == 'chapters':
                        logger.warning(f"       ç« èŠ‚è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"title={record_dict.get('title')}, "
                                        f"chapter_number={record_dict.get('chapter_number')}")
                    elif model_class.__tablename__ == 'generation_history':
                        logger.warning(f"       ç”Ÿæˆå†å²è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"chapter_id={record_dict.get('chapter_id')}, "
                                        f"model={record_dict.get('model')}")
                    elif model_class.__tablename__ == 'plot_analysis':
                        logger.warning(f"       å‰§æƒ…åˆ†æè¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"chapter_id={record_dict.get('chapter_id')}, "
                                        f"plot_stage={record_dict.get('plot_stage')}")
                    elif model_class.__tablename__ == 'analysis_tasks':
                        logger.warning(f"       åˆ†æä»»åŠ¡è¯¦æƒ…: chapter_id={record_dict.get('chapter_id')}, "
                                        f"project_id={record_dict.get('project_id')}, "
                                        f"status={record_dict.get('status')}")
                    elif model_class.__tablename__ == 'batch_generation_tasks':
                        logger.warning(f"       æ‰¹é‡ç”Ÿæˆä»»åŠ¡è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"status={record_dict.get('status')}, "
                                        f"completed={record_dict.get('completed_chapters')}/{record_dict.get('total_chapters')}")
                    elif model_class.__tablename__ == 'project_default_styles':
                        logger.warning(f"       é¡¹ç›®é»˜è®¤é£æ ¼è¯¦æƒ…: project_id={record_dict.get('project_id')}, "
                                        f"style_id={record_dict.get('style_id')}")
                    continue
                
                # æ£€æŸ¥è®°å½•æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…ä¸»é”®å†²çªï¼‰
                record_id = record_dict.get('id')
                if record_id and await self._record_exists(pg_session, model_class, record_id):
                    skipped_count += 1
                    logger.debug(f"    è·³è¿‡å·²å­˜åœ¨çš„è®°å½•: {record_id}")
                    continue
                
                # åˆ›å»ºæ–°è®°å½•
                try:
                    new_record = model_class(**record_dict)
                    pg_session.add(new_record)
                    migrated_count += 1
                except Exception as e:
                    logger.warning(f"    âš ï¸ è·³è¿‡æ— æ•ˆè®°å½•: {str(e)[:100]}")
                    skipped_count += 1
                    continue
            
            await pg_session.flush()
            
            if skipped_count > 0:
                logger.info(f"  âœ… {table_name}: {migrated_count} æ¡è®°å½•ï¼ˆè·³è¿‡ {skipped_count} æ¡æ— æ•ˆè®°å½•ï¼‰")
            else:
                logger.info(f"  âœ… {table_name}: {migrated_count} æ¡è®°å½•")
        
        except Exception as e:
            logger.error(f"  âŒ {table_name} è¿ç§»å¤±è´¥: {e}")
            raise
    
    async def _record_exists(
        self,
        pg_session: AsyncSession,
        model_class,
        record_id: Any
    ) -> bool:
        """
        æ£€æŸ¥è®°å½•æ˜¯å¦å·²å­˜åœ¨
        
        Args:
            pg_session: PostgreSQLä¼šè¯
            model_class: æ¨¡å‹ç±»
            record_id: è®°å½•ID
            
        Returns:
            bool: è®°å½•æ˜¯å¦å­˜åœ¨
        """
        try:
            # è·å–ä¸»é”®åˆ—
            pk_column = list(model_class.__table__.primary_key.columns)[0]
            result = await pg_session.execute(
                select(pk_column).where(pk_column == record_id)
            )
            return result.scalar_one_or_none() is not None
        except Exception:
            return False
    
    async def _validate_foreign_keys(
        self,
        pg_session: AsyncSession,
        model_class,
        record_dict: Dict[str, Any]
    ) -> bool:
        """
        éªŒè¯è®°å½•çš„å¤–é”®æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            pg_session: PostgreSQLä¼šè¯
            model_class: æ¨¡å‹ç±»
            record_dict: è®°å½•å­—å…¸
            
        Returns:
            bool: å¤–é”®æ˜¯å¦å…¨éƒ¨æœ‰æ•ˆ
        """
        from app.models import Character, Project, Chapter
        
        # ä½¿ç”¨no_autoflushé˜²æ­¢è¿‡æ—©flush
        with pg_session.no_autoflush:
            # é’ˆå¯¹StoryMemoryè¡¨éªŒè¯å¤–é”®
            if model_class.__tablename__ == 'story_memories':
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [è®°å¿†] æ— æ•ˆçš„project_id: {project_id}")
                        return False
                
                # éªŒè¯chapter_idï¼ˆå¯é€‰ï¼‰
                chapter_id = record_dict.get('chapter_id')
                if chapter_id:
                    result = await pg_session.execute(
                        select(Chapter.id).where(Chapter.id == chapter_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [è®°å¿†] æ— æ•ˆçš„chapter_id: {chapter_id}")
                        return False
            
            # é’ˆå¯¹CharacterRelationshipè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'character_relationships':
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ æ— æ•ˆçš„project_id: {project_id}")
                        return False
                
                # éªŒè¯character_from_id
                char_from_id = record_dict.get('character_from_id')
                if char_from_id:
                    result = await pg_session.execute(
                        select(Character.id).where(Character.id == char_from_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ æ— æ•ˆçš„character_from_id: {char_from_id}")
                        return False
                
                # éªŒè¯character_to_id
                char_to_id = record_dict.get('character_to_id')
                if char_to_id:
                    result = await pg_session.execute(
                        select(Character.id).where(Character.id == char_to_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ æ— æ•ˆçš„character_to_id: {char_to_id}")
                        return False
                
                # éªŒè¯relationship_type_id
                rel_type_id = record_dict.get('relationship_type_id')
                if rel_type_id:
                    result = await pg_session.execute(
                        select(RelationshipType.id).where(RelationshipType.id == rel_type_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ æ— æ•ˆçš„relationship_type_id: {rel_type_id}")
                        return False
        
            # é’ˆå¯¹Organizationè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'organizations':
                # éªŒè¯character_id
                char_id = record_dict.get('character_id')
                if char_id:
                    result = await pg_session.execute(
                        select(Character.id).where(Character.id == char_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [ç»„ç»‡] æ— æ•ˆçš„character_id: {char_id}")
                        return False
            
            # é’ˆå¯¹OrganizationMemberè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'organization_members':
                from app.models import Organization
                
                # éªŒè¯organization_id
                org_id = record_dict.get('organization_id')
                if org_id:
                    result = await pg_session.execute(
                        select(Organization.id).where(Organization.id == org_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ æ— æ•ˆçš„organization_id: {org_id}")
                        return False
                
                # éªŒè¯character_id
                char_id = record_dict.get('character_id')
                if char_id:
                    result = await pg_session.execute(
                        select(Character.id).where(Character.id == char_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [ç»„ç»‡æˆå‘˜] æ— æ•ˆçš„character_id: {char_id}")
                        return False
            
            # é’ˆå¯¹Characterè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'characters':
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [è§’è‰²] æ— æ•ˆçš„project_id: {project_id}")
                        return False
            
            # é’ˆå¯¹Outlineè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'outlines':
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [å¤§çº²] æ— æ•ˆçš„project_id: {project_id}")
                        return False
            
            # é’ˆå¯¹Chapterè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'chapters':
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [ç« èŠ‚] æ— æ•ˆçš„project_id: {project_id}")
                        return False
            
            # é’ˆå¯¹WritingStyleè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'writing_styles':
                # éªŒè¯project_idï¼ˆå¯é€‰ï¼‰
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [å†™ä½œé£æ ¼] æ— æ•ˆçš„project_id: {project_id}")
                        return False
            
            # é’ˆå¯¹GenerationHistoryè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'generation_history':
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [ç”Ÿæˆå†å²] æ— æ•ˆçš„project_id: {project_id}")
                        return False
                
                # éªŒè¯chapter_idï¼ˆå¯é€‰ï¼‰
                chapter_id = record_dict.get('chapter_id')
                if chapter_id:
                    result = await pg_session.execute(
                        select(Chapter.id).where(Chapter.id == chapter_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [ç”Ÿæˆå†å²] æ— æ•ˆçš„chapter_id: {chapter_id}")
                        return False
            
            # é’ˆå¯¹PlotAnalysisè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'plot_analysis':
                # éªŒè¯project_idï¼ˆå¿…éœ€ï¼‰
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [å‰§æƒ…åˆ†æ] æ— æ•ˆçš„project_id: {project_id}")
                        return False
                
                # éªŒè¯chapter_idï¼ˆå¿…éœ€ï¼‰
                chapter_id = record_dict.get('chapter_id')
                if chapter_id:
                    result = await pg_session.execute(
                        select(Chapter.id).where(Chapter.id == chapter_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [å‰§æƒ…åˆ†æ] æ— æ•ˆçš„chapter_id: {chapter_id}")
                        return False
            
            # é’ˆå¯¹AnalysisTaskè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'analysis_tasks':
                # éªŒè¯chapter_idï¼ˆå¿…éœ€ï¼‰
                chapter_id = record_dict.get('chapter_id')
                if chapter_id:
                    result = await pg_session.execute(
                        select(Chapter.id).where(Chapter.id == chapter_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [åˆ†æä»»åŠ¡] æ— æ•ˆçš„chapter_id: {chapter_id}")
                        return False
                
                # éªŒè¯project_id
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [åˆ†æä»»åŠ¡] æ— æ•ˆçš„project_id: {project_id}")
                        return False
            
            # é’ˆå¯¹BatchGenerationTaskè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'batch_generation_tasks':
                # éªŒè¯project_idï¼ˆå¿…éœ€ï¼‰
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [æ‰¹é‡ç”Ÿæˆä»»åŠ¡] æ— æ•ˆçš„project_id: {project_id}")
                        return False
            
            # é’ˆå¯¹ProjectDefaultStyleè¡¨éªŒè¯å¤–é”®
            elif model_class.__tablename__ == 'project_default_styles':
                from app.models import WritingStyle
                
                # éªŒè¯project_idï¼ˆå¿…éœ€ï¼‰
                project_id = record_dict.get('project_id')
                if project_id:
                    result = await pg_session.execute(
                        select(Project.id).where(Project.id == project_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [é¡¹ç›®é»˜è®¤é£æ ¼] æ— æ•ˆçš„project_id: {project_id}")
                        return False
                
                # éªŒè¯style_idï¼ˆå¿…éœ€ï¼‰
                style_id = record_dict.get('style_id')
                if style_id:
                    result = await pg_session.execute(
                        select(WritingStyle.id).where(WritingStyle.id == style_id)
                    )
                    if not result.scalar_one_or_none():
                        logger.warning(f"      âŒ [é¡¹ç›®é»˜è®¤é£æ ¼] æ— æ•ˆçš„style_id: {style_id}")
                        return False
        
            return True
    
    def _validate_field_lengths(
        self,
        model_class,
        record_dict: Dict[str, Any],
        table_name: str
    ) -> bool:
        """
        éªŒè¯è®°å½•çš„å­—æ®µé•¿åº¦æ˜¯å¦ç¬¦åˆæ¨¡å‹å®šä¹‰
        
        Args:
            model_class: æ¨¡å‹ç±»
            record_dict: è®°å½•å­—å…¸
            table_name: è¡¨åï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            bool: å­—æ®µé•¿åº¦æ˜¯å¦å…¨éƒ¨æœ‰æ•ˆ
        """
        from sqlalchemy import String
        
        # æ£€æŸ¥æ‰€æœ‰å­—ç¬¦ä¸²ç±»å‹å­—æ®µ
        for column in model_class.__table__.columns:
            # åªæ£€æŸ¥æœ‰é•¿åº¦é™åˆ¶çš„Stringç±»å‹å­—æ®µ
            if isinstance(column.type, String) and column.type.length:
                field_name = column.name
                field_value = record_dict.get(field_name)
                max_length = column.type.length
                
                # å¦‚æœå­—æ®µæœ‰å€¼ä¸”è¶…è¿‡æœ€å¤§é•¿åº¦
                if field_value and isinstance(field_value, str) and len(field_value) > max_length:
                    logger.warning(
                        f"      âŒ [{table_name}] å­—æ®µ '{field_name}' è¶…é•¿: "
                        f"{len(field_value)} > {max_length} (æˆªæ–­äº† {len(field_value) - max_length} å­—ç¬¦)"
                    )
                    # å¯¹äºæ•æ„Ÿå­—æ®µå¦‚APIå¯†é’¥ï¼Œè®°å½•éƒ¨åˆ†å†…å®¹
                    if field_name in ['api_key', 'api_base_url']:
                        preview = field_value[:50] + "..." + field_value[-20:] if len(field_value) > 70 else field_value
                        logger.warning(f"         å€¼é¢„è§ˆ: {preview}")
                    return False
        
        return True
    
    async def _reset_sequences(self):
        """é‡ç½®PostgreSQLçš„è‡ªå¢åºåˆ—åˆ°æ­£ç¡®çš„å€¼"""
        logger.info("\n" + "="*60)
        logger.info("é‡ç½®è‡ªå¢åºåˆ—...")
        logger.info("="*60)
        
        # éœ€è¦é‡ç½®åºåˆ—çš„è¡¨ï¼ˆä½¿ç”¨Integerè‡ªå¢ä¸»é”®çš„è¡¨ï¼‰
        tables_with_sequences = [
            ('relationship_types', 'id'),
            ('writing_styles', 'id'),
            ('project_default_styles', 'id'),
        ]
        
        async with self.pg_session_maker() as session:
            for table_name, id_column in tables_with_sequences:
                try:
                    # è·å–è¡¨ä¸­å½“å‰æœ€å¤§ID
                    result = await session.execute(
                        text(f"SELECT MAX({id_column}) FROM {table_name}")
                    )
                    max_id = result.scalar()
                    
                    if max_id is not None:
                        # é‡ç½®åºåˆ—åˆ° max_id + 1
                        sequence_name = f"{table_name}_{id_column}_seq"
                        await session.execute(
                            text(f"SELECT setval('{sequence_name}', :max_id, true)"),
                            {"max_id": max_id}
                        )
                        logger.info(f"  âœ… {table_name}: åºåˆ—é‡ç½®åˆ° {max_id}")
                    else:
                        logger.info(f"  - {table_name}: è¡¨ä¸ºç©ºï¼Œè·³è¿‡åºåˆ—é‡ç½®")
                        
                except Exception as e:
                    logger.warning(f"  âš ï¸ {table_name}: åºåˆ—é‡ç½®å¤±è´¥ - {str(e)}")
            
            await session.commit()
        
        logger.info("âœ… åºåˆ—é‡ç½®å®Œæˆ")
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.pg_engine.dispose()


async def main():
    """ä¸»å‡½æ•°"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          SQLite to PostgreSQL æ•°æ®è¿ç§»å·¥å…·                   â•‘
â•‘                                                              â•‘
â•‘  æ­¤å·¥å…·å°†SQLiteæ•°æ®è¿ç§»åˆ°PostgreSQL                          â•‘
â•‘  è¯·ç¡®ä¿:                                                     â•‘
â•‘  1. PostgreSQLæ•°æ®åº“å·²åˆ›å»º                                   â•‘
â•‘  2. .envä¸­DATABASE_URLå·²é…ç½®ä¸ºPostgreSQL                     â•‘
â•‘  3. SQLiteæ•°æ®æ–‡ä»¶å­˜åœ¨                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)
    logger.info(banner)
    
    # é…ç½®
    sqlite_dir = Path(__file__).parent.parent / "data"
    target_user_id = "migrated_user"  # é»˜è®¤ç”¨æˆ·ID
    
    config_info = f"""
é…ç½®ä¿¡æ¯:
  SQLiteç›®å½•: {sqlite_dir}
  PostgreSQL: {settings.database_url}
  ç›®æ ‡ç”¨æˆ·ID: {target_user_id}
  æ—¥å¿—æ–‡ä»¶: {log_filename}
"""
    print(config_info)
    logger.info(config_info)
    
    # ç¡®è®¤
    response = input("æ˜¯å¦ç»§ç»­è¿ç§»? (yes/no): ")
    if response.lower() not in ['yes', 'y']:
        print("å·²å–æ¶ˆè¿ç§»")
        return
    
    # æ‰§è¡Œè¿ç§»
    migrator = SQLiteToPostgresMigrator(sqlite_dir, target_user_id)
    
    try:
        await migrator.migrate_all()
        success_msg = """
ğŸ‰ æ•°æ®è¿ç§»æˆåŠŸå®Œæˆ!

ä¸‹ä¸€æ­¥:
  1. æµ‹è¯•åº”ç”¨åŠŸèƒ½
  2. éªŒè¯æ•°æ®å®Œæ•´æ€§
  3. å¤‡ä»½SQLiteæ–‡ä»¶åå¯åˆ é™¤
  
è¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {}
        """.format(log_filename)
        print(success_msg)
        logger.info(success_msg)
    
    except Exception as e:
        error_msg = f"\nâŒ è¿ç§»å¤±è´¥: {e}\nè¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {log_filename}"
        print(error_msg)
        logger.error("è¿ç§»è¿‡ç¨‹å‡ºé”™", exc_info=True)
    
    finally:
        await migrator.cleanup()
        logger.info(f"ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­ï¼Œæ—¥å¿—æ–‡ä»¶: {log_filename}")


if __name__ == "__main__":
    asyncio.run(main())